{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>unprocessed_code</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "1  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "2  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "3  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "4  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "\n",
       "                                    unprocessed_code      project  \n",
       "0  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "1  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "2  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "3  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "4  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix</th>\n",
       "      <th>text</th>\n",
       "      <th>fixdate</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>project</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:02:11</td>\n",
       "      <td>Flat3Map.Entry.setValue() overwrites other Ent...</td>\n",
       "      <td>Flat3Map&amp;amp;apos;s Entry objects will overwri...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>[org.apache.commons.collections.testextendedpr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:44:33</td>\n",
       "      <td>ExtendedProperties - field include should be n...</td>\n",
       "      <td>The field \"include\" in ExtendedProperties is c...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>[org.apache.commons.collections.testlistutils....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-18 19:01:22</td>\n",
       "      <td>CollectionUtils removeAll is actually retainAll</td>\n",
       "      <td>The removeAll(Collection collection, Collectio...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-20 14:11:54</td>\n",
       "      <td>Flat3Map.remove() does not return the correct ...</td>\n",
       "      <td>final Flat3Map m = new Flat3Map();\\n  ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[org.apache.commons.collections.fasttreemap.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-31 09:39:59</td>\n",
       "      <td>FastTreeMap forgets the comparator</td>\n",
       "      <td>In line 359 and 582 of the current 3.2 release...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fix text  \\\n",
       "id                                                            \n",
       "217  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "214  [org.apache.commons.collections.testextendedpr...  NaN   \n",
       "222  [org.apache.commons.collections.testlistutils....  NaN   \n",
       "261  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "264  [org.apache.commons.collections.fasttreemap.java]  NaN   \n",
       "\n",
       "                 fixdate                                            summary  \\\n",
       "id                                                                            \n",
       "217  2006-07-18 22:02:11  Flat3Map.Entry.setValue() overwrites other Ent...   \n",
       "214  2006-07-18 22:44:33  ExtendedProperties - field include should be n...   \n",
       "222  2006-08-18 19:01:22    CollectionUtils removeAll is actually retainAll   \n",
       "261  2007-08-20 14:11:54  Flat3Map.remove() does not return the correct ...   \n",
       "264  2007-08-31 09:39:59                 FastTreeMap forgets the comparator   \n",
       "\n",
       "                                           description      project  \\\n",
       "id                                                                    \n",
       "217  Flat3Map&amp;apos;s Entry objects will overwri...  COLLECTIONS   \n",
       "214  The field \"include\" in ExtendedProperties is c...  COLLECTIONS   \n",
       "222  The removeAll(Collection collection, Collectio...  COLLECTIONS   \n",
       "261          final Flat3Map m = new Flat3Map();\\n  ...  COLLECTIONS   \n",
       "264  In line 359 and 582 of the current 3.2 release...  COLLECTIONS   \n",
       "\n",
       "     average_precision  \n",
       "id                      \n",
       "217                0.0  \n",
       "214                0.0  \n",
       "222                0.0  \n",
       "261                0.0  \n",
       "264                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('Output/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('Output/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "\n",
    "display(all_projects_source_codes.head())\n",
    "display(all_projects_bugreports.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing New Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove next line characters:\n",
    "def remove_new_lines(text):\n",
    "    text = str(text)\n",
    "    COMBINE_WHITE_SPACE = re.compile(r\"(?a:\\s+)\")\n",
    "    text = COMBINE_WHITE_SPACE.sub(' ', text)\n",
    "    return text.replace('*', '').replace('/', '').replace('\\\\','')\n",
    "    \n",
    "# clean up the various white space and remove some *\n",
    "def clean_new_lines_source_code(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(remove_new_lines)\n",
    "    return df\n",
    "\n",
    "# clean up the description and summary, they will both be used for the query\n",
    "def clean_new_lines_bug_report(df):\n",
    "    df.summary = df.summary.apply(remove_new_lines)\n",
    "    df['description'] = df['description'].astype('|U')\n",
    "    df.description = df.description.apply(remove_new_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes file path to be just the filename + extension for source code files\n",
    "def clean_sc_file(x):\n",
    "    file = x.split(\"\\\\\")\n",
    "    return ''.join(file[-1:])\n",
    "\n",
    "# changes file path to be just the filename + extension for bug report fixes \n",
    "def clean_bug_file(x):\n",
    "    fixes = []\n",
    "\n",
    "    for file in x:\n",
    "        file = file.split(\".\")\n",
    "        file = '.'.join(file[-2:])\n",
    "        fixes.append(file)\n",
    "    return fixes\n",
    "\n",
    "\n",
    "def clean_sc_filepath(df):\n",
    "    df.filename = df.filename.map(clean_sc_file)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_bug_filepath(df):\n",
    "    df['fix'] = df['fix'].map(clean_bug_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Composite Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting composite words\n",
    "#splits using camlecase syntax\n",
    "def findCompositeWords(s):\n",
    "    return ' '.join(re.findall('[A-Z][^A-Z]*', s))   \n",
    "\n",
    "\n",
    "def clean_composite_source_code(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(findCompositeWords)\n",
    "    return df\n",
    "\n",
    "def clean_composite_bug_report(df):\n",
    "    df.summary = df.summary.apply(findCompositeWords)\n",
    "    df.description = df.description.apply(findCompositeWords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove fixes that can't be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look through the src data frame to find where the fix is. \n",
    "def get_fix_indexes(bug, src):\n",
    "    fix_list = list()\n",
    "    for fixes in bug[\"fix\"]:\n",
    "        fix_sub=list()\n",
    "        for fix in fixes:\n",
    "            df = src[src[\"filename\"].str.match(fix)]\n",
    "            if(df.shape[0] != 0):\n",
    "                fix_sub.append(df.index[0])\n",
    "            else:\n",
    "                fix_sub.append(-1)\n",
    "        fix_list.append(fix_sub)\n",
    "    # this is a list of the indexes of the file where the fix was located\n",
    "    return fix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFixesNotFound(bug, src):\n",
    "    bug[\"fix_indexes\"] = get_fix_indexes(bug, src)\n",
    "    fixes = bug.fix.tolist()\n",
    "    fix_indexes = bug.fix_indexes.tolist()\n",
    "    fixes_return = []\n",
    "    fixes_indexes_return = []\n",
    "    numFixes = []\n",
    "    for i in range(len(fixes)):\n",
    "        fixes_temp = []\n",
    "        indexes_temp = []\n",
    "        numFixes.append(len(fix_indexes[i]))\n",
    "        for l in range(len(fix_indexes[i])):\n",
    "            if fix_indexes[i][l] != -1:           \n",
    "                fixes_temp.append(fixes[i][l])\n",
    "                indexes_temp.append(fix_indexes[i][l])\n",
    "        if len(fixes_temp) == 0:\n",
    "            fixes_return.append(np.nan)\n",
    "            fixes_indexes_return.append(np.nan)\n",
    "        else:\n",
    "            fixes_return.append(fixes_temp)\n",
    "            fixes_indexes_return.append(indexes_temp)\n",
    "        \n",
    "#         print(fixes_return)\n",
    "#         print(fixes_indexes_return)\n",
    "    bug['numFixes'] = numFixes\n",
    "    bug['fix'] = fixes_return\n",
    "    bug['fix_indexes'] = fixes_indexes_return \n",
    "    \n",
    "    return bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the unprocessed code column\n",
    "def clean_source_df(df):\n",
    "    # clean up the new lines\n",
    "    df = clean_new_lines_source_code(df)\n",
    "    # clean up composite words\n",
    "    df = clean_composite_source_code(df)\n",
    "    # clean filepaths\n",
    "    df = clean_sc_filepath(df)\n",
    "    return df\n",
    "\n",
    "# add the summary and description together and clean the data\n",
    "def clean_combine_bug_df(df):\n",
    "    # clean up new lines\n",
    "    df = clean_new_lines_bug_report(df)\n",
    "    # clean composite words\n",
    "    df = clean_composite_bug_report(df)\n",
    "    # clean file path\n",
    "    df = clean_bug_filepath(df)\n",
    "    # combine summary and descriptions to create query\n",
    "    df[\"query\"] = df[\"summary\"] + df[\"description\"]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cleaning and Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_bugreports = all_projects_bugreports.dropna(axis=0, subset=['fix'], how='all')\n",
    "\n",
    "#  get clean versions of the dataframes\n",
    "sc_df = clean_source_df(all_projects_source_codes)\n",
    "br_df = clean_combine_bug_df(all_projects_bugreports)\n",
    "\n",
    "\n",
    "# remove fixes that aren't found\n",
    "br_df = removeFixesNotFound(br_df, sc_df)\n",
    "br_df = br_df.dropna(axis=0, subset=['fix','fix_indexes'], how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the clean DFs as pickle files to prevent having to clean them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df.to_pickle(\"./Output/cleanSource.pickle\")\n",
    "br_df.to_pickle(\"./Output/cleanBugs.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining stop words, keywords and operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the Java key words to the stop words\n",
    "java_keywords = [\"abstract\", \"assert**\",\"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"enum****\" \"extends\", \"final\", \"finally\", \"for\", \"goto\",\"goto*\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\",\"interface\", \"long\", \"native\", \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp**\",\"strictfp\", \"super\", \"switch\", \"synchornized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\"]\n",
    "java_operators = [\"+\", \"-\", \"*\", \"/\", \"%\", \"+=\", \"-=\", \"*=\", \"/=\", \"++\", \"--\", \"==\", \"!=\", \"<\", \">\", \"<=\", \">=\", \".\", \"[\", \"]\", \"(\",\")\", \"!\", \"~\",\"instanceof\", \"<<\", \">>\", \">>>\", \"&\", \"^\", \"|\", \"&&\", \"||\", \"?\", \":\", \"^=\", \"%=\", \"<<=\", \">>=\", \">>>=\", \"&=\"]\n",
    "stop = java_keywords + java_operators\n",
    "#contains english stop words, java keywords and java operators\n",
    "STOP_WORDS = ENGLISH_STOP_WORDS.union(stop)\n",
    "\n",
    "# remove the stem and stop words\n",
    "# takes in an array of strings returns an array of strings\n",
    "def stem_stop(text):\n",
    "    stemmer = PorterStemmer()   #\"english\"\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in STOP_WORDS]\n",
    "    text = list(map(lambda x: stemmer.stem(x), text))\n",
    "    text = ' '.join(text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Series with all the source code files and all the bug reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series with all the source code and all the\n",
    "sc_df.reset_index(drop=True, inplace=True)\n",
    "training_src = sc_df.iloc[:, 0:3].copy()\n",
    "training_src.columns = ['filename', 'query', 'project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bugs = br_df[[\"query\", \"project\"]].copy()\n",
    "training_bugs['filename'] = 'bug'\n",
    "training_bugs.reset_index(drop=True, inplace=True)\n",
    "training_bugs = training_bugs[['filename', 'query','project']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>query</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arraystack.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagutils.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beanmap.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bidimap.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12140</th>\n",
       "      <td>bug</td>\n",
       "      <td>Undertow  H T T P S listener offers no cipher ...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12141</th>\n",
       "      <td>bug</td>\n",
       "      <td>Missing null check in equals() method of  Abst...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12142</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messages comming from  Elytron - group ...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12143</th>\n",
       "      <td>bug</td>\n",
       "      <td>Elytron introduces  S S L T L S protocol const...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12144</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messages comming from  Elytron - permis...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                              query  \\\n",
       "0      arraystack.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "1             bag.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "2        bagutils.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "3         beanmap.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "4         bidimap.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "...                ...                                                ...   \n",
       "12140              bug  Undertow  H T T P S listener offers no cipher ...   \n",
       "12141              bug  Missing null check in equals() method of  Abst...   \n",
       "12142              bug  No log messages comming from  Elytron - group ...   \n",
       "12143              bug  Elytron introduces  S S L T L S protocol const...   \n",
       "12144              bug  No log messages comming from  Elytron - permis...   \n",
       "\n",
       "           project  \n",
       "0      COLLECTIONS  \n",
       "1      COLLECTIONS  \n",
       "2      COLLECTIONS  \n",
       "3      COLLECTIONS  \n",
       "4      COLLECTIONS  \n",
       "...            ...  \n",
       "12140          ELY  \n",
       "12141          ELY  \n",
       "12142          ELY  \n",
       "12143          ELY  \n",
       "12144          ELY  \n",
       "\n",
       "[12145 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two columns to create a single data frame to train the model\n",
    "training_data = pd.concat([training_src, training_bugs], ignore_index=True)\n",
    "training_data['query'] = training_data['query'].map(stem_stop)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now start training the Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min 41s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# get the tagged documents for the doc2vec model\n",
    "training_docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(list(training_data['query']))]\n",
    "training_docs\n",
    "\n",
    "# initialize model\n",
    "# vector_size = dimensionality of the feature vectors (25, 100, 200)\n",
    "# window = the max distance bweteeen the predicted word and context words \"TUNE\"\n",
    "# alpha = the initial learning rate (says that this will drop as training progresses) start at 0.05? 0.025?\n",
    "# seed = for reproducibility (MAKE SURE IT WORKS) \"TUNE\"  [says you need 1 worker for reproducibility]\n",
    "# min_count = ignore all words with a frequency lower than this\n",
    "# max_vocab size = limit RAM during vocab building every 1 million words needs 1GB of RAM\n",
    "# workers = number of worker threads used to train. \n",
    "# epochs = number of epochs over the corpus (10-20??)\n",
    "\n",
    "# time the single run\n",
    "%timeit -n1 -r1 doc_model = Doc2Vec(training_docs, vector_size=25, window=3, alpha=0.05, min_count=1, seed=42, workers=1, epochs=20)\n",
    "\n",
    "# build vocabulary\n",
    "\n",
    "# train model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6min 25s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 doc_model3 = Doc2Vec(training_docs, vector_size=200, window=3, alpha=0.05, min_count=1, seed=42, workers=1, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 6s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 doc_model5 = Doc2Vec(training_docs, vector_size=200, window=3, alpha=0.05, min_count=1, seed=42, workers=6, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently working with model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model vocabular\n",
    "tst_model = Doc2Vec(training_docs, vector_size=200, window=3, alpha=0.05, min_count=1, seed=42, workers=1, epochs=20)\n",
    "tst_model.save(\"test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>query</th>\n",
       "      <th>project</th>\n",
       "      <th>vector</th>\n",
       "      <th>doc_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arraystack.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[0.6373648, 0.36343274, -0.21556364, 0.0261671...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[0.39248475, 0.9095622, -0.31791908, -0.447419...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagutils.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[-0.3806162, 0.014073659, 0.83630836, 0.206107...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beanmap.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[-0.018915145, -0.20437856, 0.5265517, -0.2119...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bidimap.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[0.4636378, 0.3857351, -0.26127335, -0.1524405...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12140</th>\n",
       "      <td>bug</td>\n",
       "      <td>undertow H T T P S listen offer cipher suit D ...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[0.5873729, -0.26671422, 0.26491788, 0.1084738...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12141</th>\n",
       "      <td>bug</td>\n",
       "      <td>miss null check equals() method abstract permi...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[-0.41595843, -0.3777295, 0.15903723, -0.05837...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12142</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messag com elytron group assignmentelyt...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[0.10762189, 0.04025764, 0.188332, 0.17249116,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12143</th>\n",
       "      <td>bug</td>\n",
       "      <td>elytron introduc S S L T L S protocol constrai...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[-0.066642396, -0.86785316, 0.024531504, 0.084...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12144</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messag com elytron permiss assignmentel...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[0.105894886, -0.16939646, 0.21961711, 0.02162...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12145 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                              query  \\\n",
       "0      arraystack.java  licens apach softwar foundat A S F) contributo...   \n",
       "1             bag.java  licens apach softwar foundat A S F) contributo...   \n",
       "2        bagutils.java  licens apach softwar foundat A S F) contributo...   \n",
       "3         beanmap.java  licens apach softwar foundat A S F) contributo...   \n",
       "4         bidimap.java  licens apach softwar foundat A S F) contributo...   \n",
       "...                ...                                                ...   \n",
       "12140              bug  undertow H T T P S listen offer cipher suit D ...   \n",
       "12141              bug  miss null check equals() method abstract permi...   \n",
       "12142              bug  No log messag com elytron group assignmentelyt...   \n",
       "12143              bug  elytron introduc S S L T L S protocol constrai...   \n",
       "12144              bug  No log messag com elytron permiss assignmentel...   \n",
       "\n",
       "           project                                             vector  \\\n",
       "0      COLLECTIONS  [0.6373648, 0.36343274, -0.21556364, 0.0261671...   \n",
       "1      COLLECTIONS  [0.39248475, 0.9095622, -0.31791908, -0.447419...   \n",
       "2      COLLECTIONS  [-0.3806162, 0.014073659, 0.83630836, 0.206107...   \n",
       "3      COLLECTIONS  [-0.018915145, -0.20437856, 0.5265517, -0.2119...   \n",
       "4      COLLECTIONS  [0.4636378, 0.3857351, -0.26127335, -0.1524405...   \n",
       "...            ...                                                ...   \n",
       "12140          ELY  [0.5873729, -0.26671422, 0.26491788, 0.1084738...   \n",
       "12141          ELY  [-0.41595843, -0.3777295, 0.15903723, -0.05837...   \n",
       "12142          ELY  [0.10762189, 0.04025764, 0.188332, 0.17249116,...   \n",
       "12143          ELY  [-0.066642396, -0.86785316, 0.024531504, 0.084...   \n",
       "12144          ELY  [0.105894886, -0.16939646, 0.21961711, 0.02162...   \n",
       "\n",
       "      doc_vector  \n",
       "0                 \n",
       "1                 \n",
       "2                 \n",
       "3                 \n",
       "4                 \n",
       "...          ...  \n",
       "12140             \n",
       "12141             \n",
       "12142             \n",
       "12143             \n",
       "12144             \n",
       "\n",
       "[12145 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"vector\"] =\"\"\n",
    "for i in range(12145):\n",
    "    training_data[\"vector\"].iloc[i] = tst_model[i]\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data[\"vector\"].iloc[0]))\n",
    "print(len(training_data[\"vector\"].iloc[1]))\n",
    "print(len(training_data[\"vector\"].iloc[2]))\n",
    "print(len(training_data[\"vector\"].iloc[12144]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16581872], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.07493816], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0666424  -0.86785316  0.0245315   0.08457747 -0.78628224  1.4840965\n",
      "  0.6094659   0.11590197  0.4568097  -0.42331797]\n",
      "[ 0.14347313 -1.155734    1.0134165  -0.11994062 -0.18458024  0.6229553\n",
      " -0.04828192  0.03377128  0.66259235 -0.23978281]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04695935], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing some of the similarities and the .infer_vector function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosSim = cosine_similarity(training_data[\"vector\"].iloc[0].reshape(1,-1), training_data[\"vector\"].iloc[12144].reshape(1,-1)).flatten()\n",
    "display(cosSim)\n",
    "cosSim2 = cosine_similarity(training_data[\"vector\"].iloc[0].reshape(1,-1), training_data[\"vector\"].iloc[12143].reshape(1,-1)).flatten()\n",
    "display(cosSim2)\n",
    "tst_vector = tst_model.infer_vector(training_data[\"query\"].iloc[12143].split())\n",
    "\n",
    "\n",
    "# test to se what the .infer_vector function does\n",
    "print(training_data[\"vector\"].iloc[12143][:10])\n",
    "\n",
    "# the test vector comes out different every time\n",
    "print(tst_vector[:10])\n",
    "cosSim3 = cosine_similarity(training_data[\"vector\"].iloc[0].reshape(1,-1), tst_vector.reshape(1,-1)).flatten()\n",
    "cosSim3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the vector column to the orginal data frames (sc_df & br_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df[\"vector\"] = training_data.loc[0:sc_df.shape[0], 'vector']\n",
    "\n",
    "t_bugs = training_data.iloc[sc_df.shape[0]:training_data.shape[0]].copy()\n",
    "vect_list = t_bugs.vector.tolist()\n",
    "br_df['vector'] = vect_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the data again, perform same functions as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the projects \n",
    "projects = sc_df.project.unique()\n",
    "\n",
    "# group the data frames\n",
    "sc_grouped_df = sc_df.groupby(sc_df.project)\n",
    "bg_grouped_df = br_df.groupby(br_df.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run slightly different version of method 2 code to generate similarity scores\n",
    "- We don't have to train and run a vectorizer. \n",
    "- Just have to iterate through the bugs in the project and generate similarity scores between it's vector and the vector for each of the source code files (direct and indirect)\n",
    "- For each query we want to have an array of similarity scores where each item is for a source code file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Direct and Indirect scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for determining the number of terms in a source code file\n",
    "\n",
    "# min max scaler \n",
    "def custom_min_max(arr):\n",
    "    min_val = np.amin(arr)\n",
    "    max_val = np.amax(arr)\n",
    "    f = lambda x: (x - min_val) / (max_val - min_val)\n",
    "    result = f(arr)\n",
    "        \n",
    "    return result\n",
    "\n",
    "# generate number of terms based off of length of file \n",
    "def gen_num_terms(len_arr):\n",
    "    len_norm = custom_min_max(len_arr)\n",
    "    f = lambda x: 1 / (1 + np.exp(-1 * x))\n",
    "    num_terms = f(len_norm)\n",
    "    return num_terms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity when using revised Vector Space Model\n",
    "def calculate_rVSM_similarity(vect, src_vect, query_data, num_terms):\n",
    "    query = vect.transform(query_data)\n",
    "    cosSim = cosine_similarity(query, src_vect).flatten()\n",
    "#     result = np.multiply(cosSim, num_terms)\n",
    "#     return result\n",
    "\n",
    "    for i in range(len(cosSim)):\n",
    "        cosSim[i] = cosSim[i] * num_terms[i]\n",
    "    return cosSim\n",
    "\n",
    "# generates direct and indirect scores\n",
    "# source - dataframe for source code files\n",
    "# query - dataframe for \n",
    "def generate_scores_list(source, query):\n",
    "    direct_scores = []\n",
    "    indirect_scores = []\n",
    "    \n",
    "    # create hash lookup table to decrease search time for filename index.\n",
    "    lookup_table = dict()\n",
    "    names = source.filename.tolist()\n",
    "    for i in range(len(names)):\n",
    "        lookup_table[names[i]] = i\n",
    "    \n",
    "    # used to define the number of terms for each source code file\n",
    "    source_lengths = source['unprocessed_code'].map(lambda x: len(x.split()))\n",
    "    \n",
    "    # get the number of terms for each file\n",
    "    num_terms_list = gen_num_terms(source_lengths)\n",
    "    \n",
    "    # get the DIRECT and INDIRECT similarity scores for the bug reports\n",
    "    src_code_len = len(source['unprocessed_code'])\n",
    "    prev_bugs = query[\"fix\"].tolist()\n",
    "    num_fixes = query[\"numFixes\"].tolist()\n",
    "    for q in query[\"query\"]:\n",
    "        # calculate direct similarity and append it to the list\n",
    "        similarity = calculate_rVSM_similarity(vect, src_vect, [q], num_terms_list)\n",
    "        direct_scores.append(similarity)   \n",
    "        \n",
    "        # calculate indirect similarity and append it to the list\n",
    "        \n",
    "        indirect_similarity = calculate_indirect_scores(src_code_len, [q], \n",
    "                                                        query, prev_bugs, num_fixes, lookup_table)\n",
    "        indirect_scores.append(indirect_similarity)\n",
    "\n",
    "#     print(len(direct_scores))\n",
    "#     print(len(indirect_scores))\n",
    "    return direct_scores, indirect_scores\n",
    "\n",
    "# caclulate the similarity between new bugs and old bugs.\n",
    "def calculate_indirect_scores(src_len, query_data, query_df, prev_bugs, num_fixes, table):\n",
    "\n",
    " \n",
    "    \n",
    "    # np array of zeros, update the values as needed.\n",
    "    sim_scores = np.zeros(src_len)\n",
    "\n",
    "    bug_vect = vect.transform(query_df[\"query\"])\n",
    "    \n",
    "    # CAN'T COMPARE A BUG TO IT'S SELF\n",
    "    # get similarity between the query and the prev bug query\n",
    "    bugs_sim = calculate_similarity(bug_vect, query) # one of the entries should be 1\n",
    "    \n",
    "    num_bugs = len(prev_bugs)\n",
    "#     print(num_bugs)\n",
    "#     print(len(bugs_sim))\n",
    "    for indx in range(num_bugs):\n",
    "        \n",
    "#         print(\"Index: \", indx)\n",
    "\n",
    "    # get the number of fixes, used for calculating similarity\n",
    "        num_fix = num_fixes[indx]\n",
    "        \n",
    "        # for each fix find it's index in the source['filename'] column\n",
    "        for fix_indx in range(num_fix):\n",
    "#             print(\"fix index: \", fix_indx)\n",
    "#             print(\"Previous Bugs at indx:\" , prev_bugs[indx])\n",
    "#             print(\"Single bug? \" ,prev_bugs[indx][fix_indx] )\n",
    "            sim_indx = table.get(prev_bugs[indx][fix_indx])\n",
    "            if(sim_indx):\n",
    "                if(bugs_sim[indx] == 1):\n",
    "                    # don't add the similarity values if they are for the same bug\n",
    "                    pass\n",
    "                else:\n",
    "                    sim_scores[sim_indx] = sim_scores[sim_indx] + (bugs_sim[indx]/num_fix)\n",
    "            else:\n",
    "                missing_count += 1\n",
    "    # now we have a list of indirect similarity scores for a single bug and all src code files\n",
    "#     print(\"Number missing: \", missing_count)\n",
    "    return sim_scores\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank the similarity scores and Compute MAP and MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank all the similarity scores\n",
    "def rank_sim_scores(scores):\n",
    "    sim_scores = list()\n",
    "    \n",
    "    for score in scores:\n",
    "        indicies = range(len(score))\n",
    "\n",
    "        scores_tuple = tuple(zip(score,indicies))\n",
    "        sorted_tuple = sorted(scores_tuple, reverse = True)\n",
    "\n",
    "        sim_scores.append(sorted_tuple)\n",
    "    \n",
    "    return sim_scores\n",
    "\n",
    "#Checks the average precision for each bug\n",
    "def average_precision(fix_indexes,ranked_sim):\n",
    "    ap_list = list()\n",
    "    for fixes,ranked_list in zip(fix_indexes,ranked_sim):\n",
    "        hit_list = list()\n",
    "        countTrue=0\n",
    "        for i in range(len(ranked_list)):\n",
    "            # check if source file is actually where bug is located\n",
    "            if(ranked_list[i][1] in fixes):\n",
    "                countTrue+=1\n",
    "                hit_list.append(countTrue/(i+1))\n",
    "        if(countTrue != 0):\n",
    "            ap_list.append(sum(hit_list)/countTrue)\n",
    "        else:\n",
    "            ap_list.append(0)\n",
    "    return ap_list\n",
    "\n",
    "\n",
    "#reciprocal rank is 1/n, where n is the first position of a source file where the bug is located in the ranked_sim column\n",
    "def reciprocal_rank(fix_indexes,ranked_sim):\n",
    "    rr_list = list()\n",
    "    for fixes,ranked_list in zip(fix_indexes,ranked_sim):\n",
    "        rr = 0\n",
    "        for i in range(len(ranked_list)):\n",
    "            # check if source file is actually where bug is located\n",
    "            if(ranked_list[i][1] in fixes):\n",
    "                rr = 1/(i+1)\n",
    "                break\n",
    "        rr_list.append(rr)\n",
    "    return rr_list\n",
    "\n",
    "# Gets a list containing the rank of all fixes that were found in the ranked similarity list\n",
    "def get_fix_rank(bug, isCosineSim=True):\n",
    "    fix_list = list()\n",
    "    ranked_sim = 'ranked_sim'\n",
    "    if not isCosineSim:\n",
    "        ranked_sim = 'ranked_eq7_sim'\n",
    "    for index, row in bug.iterrows():\n",
    "        i_list = list()\n",
    "        for i in range(len(row[ranked_sim])):\n",
    "            if(row[ranked_sim][i][1] in row['fix_indexes']):\n",
    "                i_list.append(i+1)\n",
    "        fix_list.append(i_list)\n",
    "    return fix_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics into the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in the source code df for a project and a single query return scores\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def generate_all_scores():\n",
    "    \n",
    "    all_bugs = []\n",
    "    all_src = []\n",
    "    # iterate through the list of 12 projects\n",
    "    i = 0\n",
    "    for proj in projects:\n",
    "        print(\"Getting scores for project \",proj,\"...\")\n",
    "        # create dataframes for each project\n",
    "        src_df = sc_grouped_df.get_group(proj)\n",
    "        bug_df = bg_grouped_df.get_group(proj).copy()\n",
    "        \n",
    "        # generate the direct and indirect scores\n",
    "        direct_scores, indirect_scores = generate_scores_list(src_df, bug_df)\n",
    "        \n",
    "        #append direct scores list to the bug dataframe\n",
    "        bug_df[\"direct_sim\"] = direct_scores # the only way that the matrix is related to the src code \n",
    "                                        # is through the index.\n",
    "            \n",
    "        #append indirect scores list to bug dataframe\n",
    "        bug_df[\"indirect_sim\"] = indirect_scores\n",
    "        \n",
    "        \n",
    "        bug_df[\"fix_indexes\"] = get_fix_indexes(bug_df, src_df)\n",
    "\n",
    "        \n",
    "      \n",
    "        # maintain a list of all the dataframes\n",
    "        all_bugs.append(bug_df)\n",
    "        all_src.append(src_df)\n",
    "    # concatenate all the data frames in order    \n",
    "    all_bug_df = pd.concat(all_bugs, ignore_index=True)\n",
    "    all_src_df = pd.concat(all_src, ignore_index=True)\n",
    "    return all_bug_df, all_src_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting scores for project  COLLECTIONS ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-051402f72ee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbugs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msources\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_all_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-127-9853a77b73e2>\u001b[0m in \u001b[0;36mgenerate_all_scores\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# generate the direct and indirect scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdirect_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindirect_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_scores_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbug_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#append direct scores list to the bug dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-37a4c27f76e6>\u001b[0m in \u001b[0;36mgenerate_scores_list\u001b[1;34m(source, query)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# calculate direct similarity and append it to the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0msimilarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_rVSM_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_vect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_terms_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mdirect_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vect' is not defined"
     ]
    }
   ],
   "source": [
    "bugs, sources = generate_all_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
