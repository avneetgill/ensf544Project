{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>unprocessed_code</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "1  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "2  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "3  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "4  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "\n",
       "                                    unprocessed_code project  \n",
       "0  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "1  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "2  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "3  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "4  /**\\n * Licensed to the Apache Software Founda...   CAMEL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix</th>\n",
       "      <th>text</th>\n",
       "      <th>fixdate</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>project</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[org.apache.camel.component.file.fileconfigure...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-07-09 09:00:19</td>\n",
       "      <td>FileConfigureTest can&amp;apos;t pass in Windows box</td>\n",
       "      <td>Because of the File.separator is different bet...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[org.apache.camel.impl.servicesupport.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-07-30 16:49:10</td>\n",
       "      <td>Stop logic a bit off in ServiceSupport.java</td>\n",
       "      <td>With the current logic, during stop the servic...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[org.apache.camel.component.vm.vmcomponent.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-03 20:18:56</td>\n",
       "      <td>VM Component should extend Seda not Queue</td>\n",
       "      <td>It appears that the deprecation of the Queue c...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>[org.apache.camel.component.file.fileproducer....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-14 21:43:05</td>\n",
       "      <td>FileProducer truncates message bodies &gt; 256KB</td>\n",
       "      <td>Thanks to NIO&amp;amp;apos;s awesomely intuitive b...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[org.apache.camel.spring.camelcontextfactorybe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-17 04:42:11</td>\n",
       "      <td>ClassCastException when using GenericApplicati...</td>\n",
       "      <td>\\nCaused by: java.lang.ClassCastException:\\nor...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fix text  \\\n",
       "id                                                            \n",
       "72   [org.apache.camel.component.file.fileconfigure...  NaN   \n",
       "81         [org.apache.camel.impl.servicesupport.java]  NaN   \n",
       "85    [org.apache.camel.component.vm.vmcomponent.java]  NaN   \n",
       "105  [org.apache.camel.component.file.fileproducer....  NaN   \n",
       "103  [org.apache.camel.spring.camelcontextfactorybe...  NaN   \n",
       "\n",
       "                 fixdate                                            summary  \\\n",
       "id                                                                            \n",
       "72   2007-07-09 09:00:19   FileConfigureTest can&apos;t pass in Windows box   \n",
       "81   2007-07-30 16:49:10        Stop logic a bit off in ServiceSupport.java   \n",
       "85   2007-08-03 20:18:56          VM Component should extend Seda not Queue   \n",
       "105  2007-08-14 21:43:05      FileProducer truncates message bodies > 256KB   \n",
       "103  2007-08-17 04:42:11  ClassCastException when using GenericApplicati...   \n",
       "\n",
       "                                           description project  \\\n",
       "id                                                               \n",
       "72   Because of the File.separator is different bet...   CAMEL   \n",
       "81   With the current logic, during stop the servic...   CAMEL   \n",
       "85   It appears that the deprecation of the Queue c...   CAMEL   \n",
       "105  Thanks to NIO&amp;apos;s awesomely intuitive b...   CAMEL   \n",
       "103  \\nCaused by: java.lang.ClassCastException:\\nor...   CAMEL   \n",
       "\n",
       "     average_precision  \n",
       "id                      \n",
       "72                 0.0  \n",
       "81                 0.0  \n",
       "85                 0.0  \n",
       "105                0.0  \n",
       "103                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('GlobalOutput/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('GlobalOutput/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "\n",
    "display(all_projects_source_codes.head())\n",
    "display(all_projects_bugreports.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing New Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove next line characters:\n",
    "def remove_new_lines(text):\n",
    "    text = str(text)\n",
    "    COMBINE_WHITE_SPACE = re.compile(r\"(?a:\\s+)\")\n",
    "    text = COMBINE_WHITE_SPACE.sub(' ', text)\n",
    "    return text.replace('*', '').replace('/', '').replace('\\\\','')\n",
    "    \n",
    "# clean up the various white space and remove some *\n",
    "def clean_new_lines_source_code(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(remove_new_lines)\n",
    "    return df\n",
    "\n",
    "# clean up the description and summary, they will both be used for the query\n",
    "def clean_new_lines_bug_report(df):\n",
    "    df.summary = df.summary.apply(remove_new_lines)\n",
    "    df['description'] = df['description'].astype('|S')\n",
    "    df.description = df.description.apply(remove_new_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes file path to be just the filename + extension for source code files\n",
    "def clean_sc_file(x):\n",
    "    file = x.split(\"\\\\\")\n",
    "    return ''.join(file[-1:])\n",
    "\n",
    "# changes file path to be just the filename + extension for bug report fixes \n",
    "def clean_bug_file(x):\n",
    "    fixes = []\n",
    "\n",
    "    for file in x:\n",
    "        file = file.split(\".\")\n",
    "        file = '.'.join(file[-2:])\n",
    "        fixes.append(file)\n",
    "    return fixes\n",
    "\n",
    "\n",
    "def clean_sc_filepath(df):\n",
    "    df.filename = df.filename.map(clean_sc_file)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_bug_filepath(df):\n",
    "    df['fix'] = df['fix'].map(clean_bug_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Composite Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look through the src data frame to find where the fix is. \n",
    "def get_fix_indexes(bug, src):\n",
    "    fix_list = list()\n",
    "    for fixes in bug[\"fix\"]:\n",
    "        fix_sub=list()\n",
    "        for fix in fixes:\n",
    "            df = src[src[\"filename\"].str.match(fix)]\n",
    "            if(df.shape[0] != 0):\n",
    "                fix_sub.append(df.index[0])\n",
    "            else:\n",
    "                fix_sub.append(-1)\n",
    "        fix_list.append(fix_sub)\n",
    "    # this is a list of the indexes of the file where the fix was located\n",
    "    return fix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFixesNotFound(bug, src):\n",
    "    bug[\"fix_indexes\"] = get_fix_indexes(bug, src)\n",
    "    fixes = bug.fix.tolist()\n",
    "    fix_indexes = bug.fix_indexes.tolist()\n",
    "    fixes_return = []\n",
    "    fixes_indexes_return = []\n",
    "    for i in range(len(fixes)):\n",
    "        fixes_temp = []\n",
    "        indexes_temp = []\n",
    "        for l in range(len(fix_indexes[i])):\n",
    "            if fix_indexes[i][l] != -1:           \n",
    "                fixes_temp.append(fixes[i][l])\n",
    "                indexes_temp.append(fix_indexes[i][l])\n",
    "        if len(fixes_temp) == 0:\n",
    "            fixes_return.append(np.nan)\n",
    "            fixes_indexes_return.append(np.nan)\n",
    "        else:\n",
    "            fixes_return.append(fixes_temp)\n",
    "            fixes_indexes_return.append(indexes_temp)\n",
    "#         print(fixes_return)\n",
    "#         print(fixes_indexes_return)\n",
    "    bug['fix'] = fixes_return\n",
    "    bug['fix_indexes'] = fixes_indexes_return \n",
    "    \n",
    "    return bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the Java key words to the stop words\n",
    "java_keywords = [\"abstract\", \"assert**\",\"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"enum****\" \"extends\", \"final\", \"finally\", \"for\", \"goto\",\"goto*\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\",\"interface\", \"long\", \"native\", \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp**\",\"strictfp\", \"super\", \"switch\", \"synchornized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\"]\n",
    "java_operators = [\"+\", \"-\", \"*\", \"/\", \"%\", \"+=\", \"-=\", \"*=\", \"/=\", \"++\", \"--\", \"==\", \"!=\", \"<\", \">\", \"<=\", \">=\", \".\", \"[\", \"]\", \"(\",\")\", \"!\", \"~\",\"instanceof\", \"<<\", \">>\", \">>>\", \"&\", \"^\", \"|\", \"&&\", \"||\", \"?\", \":\", \"^=\", \"%=\", \"<<=\", \">>=\", \">>>=\", \"&=\"]\n",
    "stop = java_keywords + java_operators\n",
    "#contains english stop words, java keywords and java operators\n",
    "STOP_WORDS = ENGLISH_STOP_WORDS.union(stop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming and calling cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the stem and stop words\n",
    "# takes in an array of strings returns an array of strings\n",
    "def stem_stop(text):\n",
    "    stemmer = PorterStemmer()   #\"english\"\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in STOP_WORDS]\n",
    "    text = list(map(lambda x: stemmer.stem(x), text))\n",
    "    text = ' '.join(text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# clean up the unprocessed code column\n",
    "def clean_source_df(df):\n",
    "    # clean up the new lines\n",
    "    df = clean_new_lines_source_code(df)\n",
    "    # clean up composite words\n",
    "    df = clean_composite_source_code(df)\n",
    "    # clean filepaths\n",
    "    df = clean_sc_filepath(df)\n",
    "    return df\n",
    "\n",
    "# add the summary and description together and clean the data\n",
    "def clean_combine_bug_df(df):\n",
    "    # clean up new lines\n",
    "    df = clean_new_lines_bug_report(df)\n",
    "    # clean composite words\n",
    "    df = clean_composite_bug_report(df)\n",
    "    # clean file path\n",
    "    df = clean_bug_filepath(df)\n",
    "    # combine summary and descriptions to create query\n",
    "    df[\"query\"] = df[\"summary\"] + df[\"description\"]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cleaning and Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_bugreports = all_projects_bugreports.dropna(axis=0, subset=['fix'], how='all')\n",
    "\n",
    "#  get clean versions of the dataframes\n",
    "sc_df = clean_source_df(all_projects_source_codes)\n",
    "br_df = clean_combine_bug_df(all_projects_bugreports)\n",
    "print(\"Test shape after cleaning\")\n",
    "\n",
    "# remove fixes that aren't found\n",
    "br_df = removeFixesNotFound(br_df, sc_df)\n",
    "br_df = br_df.dropna(axis=0, subset=['fix','fix_indexes'], how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "\n",
    "### Figure out how to train this neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
