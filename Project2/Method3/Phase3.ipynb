{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>unprocessed_code</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...</td>\n",
       "      <td>/**\\n * Licensed to the Apache Software Founda...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "1  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "2  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "3  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "4  \\gitrepo\\camel-core\\src\\main\\java\\org\\apache\\c...   \n",
       "\n",
       "                                    unprocessed_code project  \n",
       "0  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "1  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "2  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "3  /**\\n * Licensed to the Apache Software Founda...   CAMEL  \n",
       "4  /**\\n * Licensed to the Apache Software Founda...   CAMEL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix</th>\n",
       "      <th>text</th>\n",
       "      <th>fixdate</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>project</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[org.apache.camel.component.file.fileconfigure...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-07-09 09:00:19</td>\n",
       "      <td>FileConfigureTest can&amp;apos;t pass in Windows box</td>\n",
       "      <td>Because of the File.separator is different bet...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[org.apache.camel.impl.servicesupport.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-07-30 16:49:10</td>\n",
       "      <td>Stop logic a bit off in ServiceSupport.java</td>\n",
       "      <td>With the current logic, during stop the servic...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[org.apache.camel.component.vm.vmcomponent.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-03 20:18:56</td>\n",
       "      <td>VM Component should extend Seda not Queue</td>\n",
       "      <td>It appears that the deprecation of the Queue c...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>[org.apache.camel.component.file.fileproducer....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-14 21:43:05</td>\n",
       "      <td>FileProducer truncates message bodies &gt; 256KB</td>\n",
       "      <td>Thanks to NIO&amp;amp;apos;s awesomely intuitive b...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[org.apache.camel.spring.camelcontextfactorybe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-17 04:42:11</td>\n",
       "      <td>ClassCastException when using GenericApplicati...</td>\n",
       "      <td>\\nCaused by: java.lang.ClassCastException:\\nor...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fix text  \\\n",
       "id                                                            \n",
       "72   [org.apache.camel.component.file.fileconfigure...  NaN   \n",
       "81         [org.apache.camel.impl.servicesupport.java]  NaN   \n",
       "85    [org.apache.camel.component.vm.vmcomponent.java]  NaN   \n",
       "105  [org.apache.camel.component.file.fileproducer....  NaN   \n",
       "103  [org.apache.camel.spring.camelcontextfactorybe...  NaN   \n",
       "\n",
       "                 fixdate                                            summary  \\\n",
       "id                                                                            \n",
       "72   2007-07-09 09:00:19   FileConfigureTest can&apos;t pass in Windows box   \n",
       "81   2007-07-30 16:49:10        Stop logic a bit off in ServiceSupport.java   \n",
       "85   2007-08-03 20:18:56          VM Component should extend Seda not Queue   \n",
       "105  2007-08-14 21:43:05      FileProducer truncates message bodies > 256KB   \n",
       "103  2007-08-17 04:42:11  ClassCastException when using GenericApplicati...   \n",
       "\n",
       "                                           description project  \\\n",
       "id                                                               \n",
       "72   Because of the File.separator is different bet...   CAMEL   \n",
       "81   With the current logic, during stop the servic...   CAMEL   \n",
       "85   It appears that the deprecation of the Queue c...   CAMEL   \n",
       "105  Thanks to NIO&amp;apos;s awesomely intuitive b...   CAMEL   \n",
       "103  \\nCaused by: java.lang.ClassCastException:\\nor...   CAMEL   \n",
       "\n",
       "     average_precision  \n",
       "id                      \n",
       "72                 0.0  \n",
       "81                 0.0  \n",
       "85                 0.0  \n",
       "105                0.0  \n",
       "103                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('GlobalOutput/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('GlobalOutput/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "\n",
    "display(all_projects_source_codes.head())\n",
    "display(all_projects_bugreports.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing New Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove next line characters:\n",
    "def remove_new_lines(text):\n",
    "    text = str(text)\n",
    "    COMBINE_WHITE_SPACE = re.compile(r\"(?a:\\s+)\")\n",
    "    text = COMBINE_WHITE_SPACE.sub(' ', text)\n",
    "    return text.replace('*', '').replace('/', '').replace('\\\\','')\n",
    "    \n",
    "# clean up the various white space and remove some *\n",
    "def clean_new_lines_source_code(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(remove_new_lines)\n",
    "    return df\n",
    "\n",
    "# clean up the description and summary, they will both be used for the query\n",
    "def clean_new_lines_bug_report(df):\n",
    "    df.summary = df.summary.apply(remove_new_lines)\n",
    "    df['description'] = df['description'].astype('|U')\n",
    "    df.description = df.description.apply(remove_new_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes file path to be just the filename + extension for source code files\n",
    "def clean_sc_file(x):\n",
    "    file = x.split(\"\\\\\")\n",
    "    return ''.join(file[-1:])\n",
    "\n",
    "# changes file path to be just the filename + extension for bug report fixes \n",
    "def clean_bug_file(x):\n",
    "    fixes = []\n",
    "\n",
    "    for file in x:\n",
    "        file = file.split(\".\")\n",
    "        file = '.'.join(file[-2:])\n",
    "        fixes.append(file)\n",
    "    return fixes\n",
    "\n",
    "\n",
    "def clean_sc_filepath(df):\n",
    "    df.filename = df.filename.map(clean_sc_file)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_bug_filepath(df):\n",
    "    df['fix'] = df['fix'].map(clean_bug_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Composite Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting composite words\n",
    "#splits using camlecase syntax\n",
    "def findCompositeWords(s):\n",
    "    return ' '.join(re.findall('[A-Z][^A-Z]*', s))   \n",
    "\n",
    "\n",
    "def clean_composite_source_code(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(findCompositeWords)\n",
    "    return df\n",
    "\n",
    "def clean_composite_bug_report(df):\n",
    "    df.summary = df.summary.apply(findCompositeWords)\n",
    "    df.description = df.description.apply(findCompositeWords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove fixes that can't be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look through the src data frame to find where the fix is. \n",
    "def get_fix_indexes(bug, src):\n",
    "    fix_list = list()\n",
    "    for fixes in bug[\"fix\"]:\n",
    "        fix_sub=list()\n",
    "        for fix in fixes:\n",
    "            df = src[src[\"filename\"].str.match(fix)]\n",
    "            if(df.shape[0] != 0):\n",
    "                fix_sub.append(df.index[0])\n",
    "            else:\n",
    "                fix_sub.append(-1)\n",
    "        fix_list.append(fix_sub)\n",
    "    # this is a list of the indexes of the file where the fix was located\n",
    "    return fix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFixesNotFound(bug, src):\n",
    "    bug[\"fix_indexes\"] = get_fix_indexes(bug, src)\n",
    "    fixes = bug.fix.tolist()\n",
    "    fix_indexes = bug.fix_indexes.tolist()\n",
    "    fixes_return = []\n",
    "    fixes_indexes_return = []\n",
    "    numFixes = []\n",
    "    for i in range(len(fixes)):\n",
    "        fixes_temp = []\n",
    "        indexes_temp = []\n",
    "        numFixes.append(len(fix_indexes[i]))\n",
    "        for l in range(len(fix_indexes[i])):\n",
    "            if fix_indexes[i][l] != -1:           \n",
    "                fixes_temp.append(fixes[i][l])\n",
    "                indexes_temp.append(fix_indexes[i][l])\n",
    "        if len(fixes_temp) == 0:\n",
    "            fixes_return.append(np.nan)\n",
    "            fixes_indexes_return.append(np.nan)\n",
    "        else:\n",
    "            fixes_return.append(fixes_temp)\n",
    "            fixes_indexes_return.append(indexes_temp)\n",
    "        \n",
    "#         print(fixes_return)\n",
    "#         print(fixes_indexes_return)\n",
    "    bug['numFixes'] = numFixes\n",
    "    bug['fix'] = fixes_return\n",
    "    bug['fix_indexes'] = fixes_indexes_return \n",
    "    \n",
    "    return bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the unprocessed code column\n",
    "def clean_source_df(df):\n",
    "    # clean up the new lines\n",
    "    df = clean_new_lines_source_code(df)\n",
    "    # clean up composite words\n",
    "    df = clean_composite_source_code(df)\n",
    "    # clean filepaths\n",
    "    df = clean_sc_filepath(df)\n",
    "    return df\n",
    "\n",
    "# add the summary and description together and clean the data\n",
    "def clean_combine_bug_df(df):\n",
    "    # clean up new lines\n",
    "    df = clean_new_lines_bug_report(df)\n",
    "    # clean composite words\n",
    "    df = clean_composite_bug_report(df)\n",
    "    # clean file path\n",
    "    df = clean_bug_filepath(df)\n",
    "    # combine summary and descriptions to create query\n",
    "    df[\"query\"] = df[\"summary\"] + df[\"description\"]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cleaning and Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_bugreports = all_projects_bugreports.dropna(axis=0, subset=['fix'], how='all')\n",
    "\n",
    "#  get clean versions of the dataframes\n",
    "sc_df = clean_source_df(all_projects_source_codes)\n",
    "br_df = clean_combine_bug_df(all_projects_bugreports)\n",
    "\n",
    "\n",
    "# remove fixes that aren't found\n",
    "br_df = removeFixesNotFound(br_df, sc_df)\n",
    "br_df = br_df.dropna(axis=0, subset=['fix','fix_indexes'], how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the clean DFs as pickle files to prevent having to clean them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df.to_pickle(\"./GlobalOutput/cleanSource.pickle\")\n",
    "br_df.to_pickle(\"./GlobalOutput/cleanBugs.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining stop words, keywords and operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the Java key words to the stop words\n",
    "java_keywords = [\"abstract\", \"assert**\",\"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"enum****\" \"extends\", \"final\", \"finally\", \"for\", \"goto\",\"goto*\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\",\"interface\", \"long\", \"native\", \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp**\",\"strictfp\", \"super\", \"switch\", \"synchornized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\"]\n",
    "java_operators = [\"+\", \"-\", \"*\", \"/\", \"%\", \"+=\", \"-=\", \"*=\", \"/=\", \"++\", \"--\", \"==\", \"!=\", \"<\", \">\", \"<=\", \">=\", \".\", \"[\", \"]\", \"(\",\")\", \"!\", \"~\",\"instanceof\", \"<<\", \">>\", \">>>\", \"&\", \"^\", \"|\", \"&&\", \"||\", \"?\", \":\", \"^=\", \"%=\", \"<<=\", \">>=\", \">>>=\", \"&=\"]\n",
    "stop = java_keywords + java_operators\n",
    "#contains english stop words, java keywords and java operators\n",
    "STOP_WORDS = ENGLISH_STOP_WORDS.union(stop)\n",
    "\n",
    "# remove the stem and stop words\n",
    "# takes in an array of strings returns an array of strings\n",
    "def stem_stop(text):\n",
    "    stemmer = PorterStemmer()   #\"english\"\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in STOP_WORDS]\n",
    "    text = list(map(lambda x: stemmer.stem(x), text))\n",
    "    text = ' '.join(text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Series with all the source code files and all the bug reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series with all the source code and all the\n",
    "sc_df.reset_index(drop=True, inplace=True)\n",
    "training_src = sc_df.iloc[:, 0:3].copy()\n",
    "training_src.columns = ['filename', 'query', 'project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bugs = br_df[[\"query\", \"project\"]].copy()\n",
    "training_bugs['filename'] = 'bug'\n",
    "training_bugs.reset_index(drop=True, inplace=True)\n",
    "training_bugs = training_bugs[['filename', 'query','project']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>query</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alreadystoppedexception.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asynccallback.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asyncprocessor.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asyncproducercallback.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attachments.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82377</th>\n",
       "      <td>bug</td>\n",
       "      <td>X M L parser load eagerlyw need make use A P I...</td>\n",
       "      <td>WFLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82378</th>\n",
       "      <td>bug</td>\n",
       "      <td>cluster X M L reader load eagerlyp M] radoslav...</td>\n",
       "      <td>WFLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82379</th>\n",
       "      <td>bug</td>\n",
       "      <td>cannot commun server port offset properti seti...</td>\n",
       "      <td>WFMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82380</th>\n",
       "      <td>bug</td>\n",
       "      <td>commands#fail On error default fals unless set...</td>\n",
       "      <td>WFMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82381</th>\n",
       "      <td>bug</td>\n",
       "      <td>the wild fli plugin&amp;apos; shutdown(reload=true...</td>\n",
       "      <td>WFMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82382 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "0      alreadystoppedexception.java   \n",
       "1                asynccallback.java   \n",
       "2               asyncprocessor.java   \n",
       "3        asyncproducercallback.java   \n",
       "4                  attachments.java   \n",
       "...                             ...   \n",
       "82377                           bug   \n",
       "82378                           bug   \n",
       "82379                           bug   \n",
       "82380                           bug   \n",
       "82381                           bug   \n",
       "\n",
       "                                                   query project  \n",
       "0      licens apach softwar foundat A S F) contributo...   CAMEL  \n",
       "1      licens apach softwar foundat A S F) contributo...   CAMEL  \n",
       "2      licens apach softwar foundat A S F) contributo...   CAMEL  \n",
       "3      licens apach softwar foundat A S F) contributo...   CAMEL  \n",
       "4      licens apach softwar foundat A S F) contributo...   CAMEL  \n",
       "...                                                  ...     ...  \n",
       "82377  X M L parser load eagerlyw need make use A P I...    WFLY  \n",
       "82378  cluster X M L reader load eagerlyp M] radoslav...    WFLY  \n",
       "82379  cannot commun server port offset properti seti...    WFMP  \n",
       "82380  commands#fail On error default fals unless set...    WFMP  \n",
       "82381  the wild fli plugin&apos; shutdown(reload=true...    WFMP  \n",
       "\n",
       "[82382 rows x 3 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two columns to create a single data frame to train the model\n",
    "training_data = pd.concat([training_src, training_bugs], ignore_index=True)\n",
    "training_data['query'] = training_data['query'].map(stem_stop)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_pickle(\"./GlobalOutput/cleanTrainingData.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now start training the Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-17 16:24:39.344846\n",
      "2020-12-17 16:41:51.378098\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-255-d9b4c5926d38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdateTimeObj2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdoc_model_pvdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mdoc_model_pvdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pvdm_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, documents, corpus_file, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                 end_alpha=self.min_alpha, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             **kwargs)\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0;32m    551\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    486\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0;32m    487\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from datetime import datetime\n",
    "# get the tagged documents for the doc2vec model\n",
    "training_docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(list(training_data['query']))]\n",
    "training_docs\n",
    "\n",
    "# initialize model\n",
    "# dm = 0 This will set the model to use DBOW and not DMPV\n",
    "# vector_size = 300\n",
    "# window = DBOW = 15, DMPV = 5\n",
    "# alpha = 0.01\n",
    "# min_alpha = 0.0001\n",
    "# seed = for reproducibility (MAKE SURE IT WORKS) \"TUNE\"  [says you need 1 worker for reproducibility]\n",
    "# min_count = 1\n",
    "# workers = number of worker threads used to train. \n",
    "# epochs = DBOW = 20, DMPV = 600\n",
    "\n",
    "# time the single run with 6 workers Started at 2:43\n",
    "\n",
    "dateTimeObj1 = datetime.now()\n",
    "print(dateTimeObj1)\n",
    "doc_model_dbow = Doc2Vec(training_docs, dm=0, vector_size=300, window=15, alpha=0.01, min_alpha=0.0001, min_count=1, seed=42, workers=6, epochs=20)\n",
    "doc_model_dbow.save(\"dbow_model\")\n",
    "\n",
    "dateTimeObj2 = datetime.now()\n",
    "print(dateTimeObj2)\n",
    "\n",
    "doc_model_pvdm = Doc2Vec(training_docs, dm=1, vector_size=300, window=5, alpha=0.01, min_alpha=0.0001, min_count=1, seed=42, workers=6, epochs=600)\n",
    "doc_model_pvdm.save(\"pvdm_model\")\n",
    "\n",
    "dateTimeObj3 = datetime.now()\n",
    "print(dateTimeObj3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>query</th>\n",
       "      <th>project</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alreadystoppedexception.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>[-0.11593803, 0.3264231, -0.39266086, -0.17832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asynccallback.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>[-0.09054362, 0.2255133, -0.33315194, -0.30768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asyncprocessor.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>[0.14799617, 0.19888866, -0.36354512, -0.49668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asyncproducercallback.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>[0.01663894, 0.16521521, -0.1554454, -0.478559...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attachments.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>CAMEL</td>\n",
       "      <td>[-0.072032474, 0.084826775, 0.0063502714, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82377</th>\n",
       "      <td>bug</td>\n",
       "      <td>X M L parser load eagerlyw need make use A P I...</td>\n",
       "      <td>WFLY</td>\n",
       "      <td>[-0.004771417, 0.17575903, -0.24528211, -0.152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82378</th>\n",
       "      <td>bug</td>\n",
       "      <td>cluster X M L reader load eagerlyp M] radoslav...</td>\n",
       "      <td>WFLY</td>\n",
       "      <td>[-0.047766443, 0.122389704, -0.3051204, -0.101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82379</th>\n",
       "      <td>bug</td>\n",
       "      <td>cannot commun server port offset properti seti...</td>\n",
       "      <td>WFMP</td>\n",
       "      <td>[0.08153363, 0.35014084, -0.09306045, -0.25451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82380</th>\n",
       "      <td>bug</td>\n",
       "      <td>commands#fail On error default fals unless set...</td>\n",
       "      <td>WFMP</td>\n",
       "      <td>[-0.044513583, 0.27791062, -0.1961836, 0.01690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82381</th>\n",
       "      <td>bug</td>\n",
       "      <td>the wild fli plugin&amp;apos; shutdown(reload=true...</td>\n",
       "      <td>WFMP</td>\n",
       "      <td>[-0.008247424, 0.17418937, -0.1584257, -0.2194...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "0      alreadystoppedexception.java   \n",
       "1                asynccallback.java   \n",
       "2               asyncprocessor.java   \n",
       "3        asyncproducercallback.java   \n",
       "4                  attachments.java   \n",
       "...                             ...   \n",
       "82377                           bug   \n",
       "82378                           bug   \n",
       "82379                           bug   \n",
       "82380                           bug   \n",
       "82381                           bug   \n",
       "\n",
       "                                                   query project  \\\n",
       "0      licens apach softwar foundat A S F) contributo...   CAMEL   \n",
       "1      licens apach softwar foundat A S F) contributo...   CAMEL   \n",
       "2      licens apach softwar foundat A S F) contributo...   CAMEL   \n",
       "3      licens apach softwar foundat A S F) contributo...   CAMEL   \n",
       "4      licens apach softwar foundat A S F) contributo...   CAMEL   \n",
       "...                                                  ...     ...   \n",
       "82377  X M L parser load eagerlyw need make use A P I...    WFLY   \n",
       "82378  cluster X M L reader load eagerlyp M] radoslav...    WFLY   \n",
       "82379  cannot commun server port offset properti seti...    WFMP   \n",
       "82380  commands#fail On error default fals unless set...    WFMP   \n",
       "82381  the wild fli plugin&apos; shutdown(reload=true...    WFMP   \n",
       "\n",
       "                                                  vector  \n",
       "0      [-0.11593803, 0.3264231, -0.39266086, -0.17832...  \n",
       "1      [-0.09054362, 0.2255133, -0.33315194, -0.30768...  \n",
       "2      [0.14799617, 0.19888866, -0.36354512, -0.49668...  \n",
       "3      [0.01663894, 0.16521521, -0.1554454, -0.478559...  \n",
       "4      [-0.072032474, 0.084826775, 0.0063502714, -0.2...  \n",
       "...                                                  ...  \n",
       "82377  [-0.004771417, 0.17575903, -0.24528211, -0.152...  \n",
       "82378  [-0.047766443, 0.122389704, -0.3051204, -0.101...  \n",
       "82379  [0.08153363, 0.35014084, -0.09306045, -0.25451...  \n",
       "82380  [-0.044513583, 0.27791062, -0.1961836, 0.01690...  \n",
       "82381  [-0.008247424, 0.17418937, -0.1584257, -0.2194...  \n",
       "\n",
       "[82382 rows x 4 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"vector\"] =\"\"\n",
    "for i in range(82382):\n",
    "    training_data[\"vector\"].iloc[i] = doc_model[i]\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# all of the vectors have 300 dimensions\n",
    "print(len(training_data[\"vector\"].iloc[0]))\n",
    "print(len(training_data[\"vector\"].iloc[1]))\n",
    "print(len(training_data[\"vector\"].iloc[82381]))\n",
    "print(len(training_data[\"vector\"].iloc[12144]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1862311], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.44858396], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(82382,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "82382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.44858396, 0.40365702, 0.41283527, ..., 0.17609774, 0.18451622,\n",
       "       0.33470625], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82382\n"
     ]
    }
   ],
   "source": [
    "# testing some of the similarities and the .infer_vector function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosSim = cosine_similarity(training_data[\"vector\"].iloc[0].reshape(1,-1), training_data[\"vector\"].iloc[12144].reshape(1,-1)).flatten()\n",
    "display(cosSim)\n",
    "cosSim2 = cosine_similarity(training_data[\"vector\"].iloc[0].reshape(1,-1), training_data[\"vector\"].iloc[12143].reshape(1,-1)).flatten()\n",
    "display(cosSim2)\n",
    "tst_vector = tst_model.infer_vector(training_data[\"query\"].iloc[12143].split())\n",
    "\n",
    "\n",
    "display(training_data[\"vector\"].shape)\n",
    "lst_vects = training_data[\"vector\"].tolist()\n",
    "display(len(lst_vects))\n",
    "print(\"list\")\n",
    "simList = cosine_similarity(training_data['vector'].iloc[12143].reshape(1,-1), lst_vects).flatten()\n",
    "display(simList)\n",
    "print(len(simList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the vector column to the orginal data frames (sc_df & br_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df[\"vector\"] = training_data.loc[0:sc_df.shape[0], 'vector']\n",
    "\n",
    "t_bugs = training_data.iloc[sc_df.shape[0]:training_data.shape[0]].copy()\n",
    "vect_list = t_bugs.vector.tolist()\n",
    "br_df['vector'] = vect_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the data again, perform same functions as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the projects \n",
    "projects = sc_df.project.unique()\n",
    "\n",
    "# group the data frames\n",
    "sc_grouped_df = sc_df.groupby(sc_df.project)\n",
    "bg_grouped_df = br_df.groupby(br_df.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run slightly different version of method 2 code to generate similarity scores\n",
    "- We don't have to train and run a vectorizer. \n",
    "- Just have to iterate through the bugs in the project and generate similarity scores between it's vector and the vector for each of the source code files (direct and indirect)\n",
    "- For each query we want to have an array of similarity scores where each item is for a source code file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Direct and Indirect scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for determining the number of terms in a source code file\n",
    "\n",
    "# min max scaler \n",
    "def custom_min_max(arr):\n",
    "    min_val = np.amin(arr)\n",
    "    max_val = np.amax(arr)\n",
    "    f = lambda x: (x - min_val) / (max_val - min_val)\n",
    "    result = f(arr)\n",
    "        \n",
    "    return result\n",
    "\n",
    "# generate number of terms based off of length of file \n",
    "def gen_num_terms(len_arr):\n",
    "    len_norm = custom_min_max(len_arr)\n",
    "    f = lambda x: 1 / (1 + np.exp(-1 * x))\n",
    "    num_terms = f(len_norm)\n",
    "    return num_terms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity when using revised Vector Space Model\n",
    "def calculate_rVSM_similarity(src_vect, query, num_terms):\n",
    "    result = []\n",
    "    cosSim = cosine_similarity(query.reshape(1,-1), src_vect).flatten()\n",
    "  \n",
    "    for i in range(len(cosSim)):   \n",
    "        result.append(cosSim[i] * num_terms[i])\n",
    "    return cosSim\n",
    "\n",
    "# calculate the similarity when using basic cosine similarity, used in indirect similarity calculation   \n",
    "def calculate_similarity(src_vect, query):    \n",
    "    cosSim = cosine_similarity(query.reshape(1,-1), src_vect).flatten()\n",
    "    return cosSim\n",
    "\n",
    "\n",
    "# generates direct and indirect scores\n",
    "# source - dataframe for source code files\n",
    "# query - dataframe for \n",
    "def generate_scores_list(source, query):\n",
    "    direct_scores = []\n",
    "    indirect_scores = []\n",
    "    \n",
    "    # create hash lookup table to decrease search time for filename index.\n",
    "    lookup_table = dict()\n",
    "    names = source.filename.tolist()\n",
    "    for i in range(len(names)):\n",
    "        lookup_table[names[i]] = i\n",
    "    \n",
    "    # used to define the number of terms for each source code file\n",
    "    source_lengths = source['unprocessed_code'].map(lambda x: len(x.split())).tolist()\n",
    "    \n",
    "    # get the number of terms for each file\n",
    "    num_terms_list = gen_num_terms(source_lengths)\n",
    "    \n",
    "    # get the DIRECT and INDIRECT similarity scores for the bug reports\n",
    "    src_vects = source['vector'].tolist()\n",
    "    src_code_len = len(source['unprocessed_code'])\n",
    "    prev_bug_fixes = query[\"fix\"].tolist()\n",
    "    num_fixes = query[\"numFixes\"].tolist()\n",
    "    prev_vects = query['vector'].tolist()\n",
    "    \n",
    "    for q in prev_vects:\n",
    "        # calculate direct similarity and append it to the list\n",
    "        similarity = calculate_rVSM_similarity(src_vects, q, num_terms_list)\n",
    "        direct_scores.append(similarity)\n",
    "\n",
    "        \n",
    "#         print(\"Its length: \", len(similarity))\n",
    "#         print(\"Min: \", min(similarity))\n",
    "#         print(\"Max: \", max(similarity))\n",
    "\n",
    "\n",
    "        # calculate indirect similarity and append it to the list\n",
    "        \n",
    "        # num_fixes is the previous number of fixes, not how many remain in the array\n",
    "        indirect_similarity = calculate_indirect_scores(src_code_len, q, prev_vects, \n",
    "                                                        prev_bug_fixes, num_fixes, lookup_table)\n",
    "        indirect_scores.append(indirect_similarity)\n",
    "\n",
    "   \n",
    "    return direct_scores, indirect_scores\n",
    "\n",
    "# caclulate the similarity between new bugs and old bugs.\n",
    "def calculate_indirect_scores(src_len, query_vect, prev_vects, prev_bugs, num_fixes, table):\n",
    "    sim_1 = 0\n",
    "    # np array of zeros, indexed to match the source code files.\n",
    "    sim_scores = np.zeros(src_len)\n",
    "    \n",
    "    # CAN'T COMPARE A BUG TO IT'S SELF\n",
    "    # get similarities between the query and all the prev bug query\n",
    "    bugs_sim = calculate_similarity(prev_vects, query_vect) # one of the entries should be 1\n",
    "    \n",
    "#     print(\"Min: \", min(bugs_sim))\n",
    "#     print(\"Max: \", max(bugs_sim))\n",
    "\n",
    "    num_bugs = len(prev_bugs)\n",
    "\n",
    "    # for every bug find where it's fixes were found and update the similarity score \n",
    "    #    at that index in the sim_scores add the similarity score\n",
    "    for indx in range(num_bugs):\n",
    "        \n",
    "    # get the number of fixes, used for calculating similarity\n",
    "        num_fix = num_fixes[indx]\n",
    "        \n",
    "\n",
    "#         print(\"The original number of fixes: \", num_fixes[indx])\n",
    "#         print(\"The current number of fixes: \", len(prev_bugs[indx]))\n",
    "#         print(prev_bugs[indx])\n",
    "\n",
    "\n",
    "        # for each fix find it's index in the source['filename'] column\n",
    "        for fix_indx in range(len(prev_bugs[indx])):\n",
    "\n",
    "            sim_indx = table.get(prev_bugs[indx][fix_indx])\n",
    "            if(sim_indx):\n",
    "                if(math.isclose(bugs_sim[indx], 1, abs_tol=0.0001)):\n",
    "                    # don't add the similarity values if they are for the same bug\n",
    "                    sim_1 +=1\n",
    "                    pass\n",
    "                else:\n",
    "                    sim_scores[sim_indx] = sim_scores[sim_indx] + (bugs_sim[indx]/num_fix)\n",
    "\n",
    "    # now we have a list of indirect similarity scores for a single bug and all src code files\n",
    "\n",
    "    \n",
    "#     print(\"The number of similarities = 1: \", sim_1)\n",
    "#     print(\"It should be: \" , num_fixes)\n",
    "    return sim_scores\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank the similarity scores and Compute MAP and MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank all the similarity scores\n",
    "def rank_sim_scores(scores):\n",
    "    sim_scores = list()\n",
    "    \n",
    "    for score in scores:\n",
    "        indicies = range(len(score))\n",
    "\n",
    "        scores_tuple = tuple(zip(score,indicies))\n",
    "        sorted_tuple = sorted(scores_tuple, reverse = True)\n",
    "\n",
    "        sim_scores.append(sorted_tuple)\n",
    "    \n",
    "    return sim_scores\n",
    "\n",
    "#Checks the average precision for each bug\n",
    "def average_precision(fix_indexes,ranked_sim):\n",
    "    ap_list = list()\n",
    "    for fixes,ranked_list in zip(fix_indexes,ranked_sim):\n",
    "        hit_list = list()\n",
    "        countTrue=0\n",
    "        for i in range(len(ranked_list)):\n",
    "            # check if source file is actually where bug is located\n",
    "            if(ranked_list[i][1] in fixes):\n",
    "                countTrue+=1\n",
    "                hit_list.append(countTrue/(i+1))\n",
    "        if(countTrue != 0):\n",
    "            ap_list.append(sum(hit_list)/countTrue)\n",
    "        else:\n",
    "            ap_list.append(0)\n",
    "    return ap_list\n",
    "\n",
    "\n",
    "#reciprocal rank is 1/n, where n is the first position of a source file where the bug is located in the ranked_sim column\n",
    "def reciprocal_rank(fix_indexes,ranked_sim):\n",
    "    rr_list = list()\n",
    "    for fixes,ranked_list in zip(fix_indexes,ranked_sim):\n",
    "        rr = 0\n",
    "        for i in range(len(ranked_list)):\n",
    "            # check if source file is actually where bug is located\n",
    "            if(ranked_list[i][1] in fixes):\n",
    "                rr = 1/(i+1)\n",
    "                break\n",
    "        rr_list.append(rr)\n",
    "    return rr_list\n",
    "\n",
    "# Gets a list containing the rank of all fixes that were found in the ranked similarity list\n",
    "def get_fix_rank(bug, isCosineSim=True):\n",
    "    fix_list = list()\n",
    "    ranked_sim = 'ranked_sim'\n",
    "    if not isCosineSim:\n",
    "        ranked_sim = 'ranked_eq7_sim'\n",
    "    for index, row in bug.iterrows():\n",
    "        i_list = list()\n",
    "        for i in range(len(row[ranked_sim])):\n",
    "            if(row[ranked_sim][i][1] in row['fix_indexes']):\n",
    "                i_list.append(i+1)\n",
    "        fix_list.append(i_list)\n",
    "    return fix_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics into the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in the source code df for a project and a single query return scores\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "projects2 = projects[1:2]\n",
    "\n",
    "def generate_all_scores():\n",
    "    \n",
    "    all_bugs = []\n",
    "    all_src = []\n",
    "    # iterate through the list of 12 projects\n",
    "    for proj in projects:\n",
    "        print(\"Getting scores for project \",proj,\"...\")\n",
    "        # create dataframes for each project\n",
    "        src_df = sc_grouped_df.get_group(proj)\n",
    "        bug_df = bg_grouped_df.get_group(proj).copy()\n",
    "        \n",
    "        # generate the direct and indirect scores\n",
    "        direct_scores, indirect_scores = generate_scores_list(src_df, bug_df)\n",
    "        \n",
    "        #append direct scores list to the bug dataframe\n",
    "        bug_df[\"direct_sim\"] = direct_scores # the only way that the matrix is related to the src code \n",
    "                                        # is through the index.\n",
    "            \n",
    "        #append indirect scores list to bug dataframe\n",
    "        bug_df[\"indirect_sim\"] = indirect_scores\n",
    "        \n",
    "        \n",
    "        bug_df[\"fix_indexes\"] = get_fix_indexes(bug_df, src_df)\n",
    "\n",
    "        \n",
    "      \n",
    "        # maintain a list of all the dataframes\n",
    "        all_bugs.append(bug_df)\n",
    "        all_src.append(src_df)\n",
    "    # concatenate all the data frames in order    \n",
    "    all_bug_df = pd.concat(all_bugs, ignore_index=True)\n",
    "    all_src_df = pd.concat(all_src, ignore_index=True)\n",
    "    return all_bug_df, all_src_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting scores for project  COLLECTIONS ...\n",
      "Getting scores for project  CONFIGURATION ...\n",
      "Getting scores for project  IO ...\n",
      "Getting scores for project  LANG ...\n",
      "Getting scores for project  DATACMNS ...\n",
      "Getting scores for project  DATAMONGO ...\n",
      "Getting scores for project  DATAREST ...\n",
      "Getting scores for project  LDAP ...\n",
      "Getting scores for project  SEC ...\n",
      "Getting scores for project  SOCIALFB ...\n",
      "Getting scores for project  SPR ...\n",
      "Getting scores for project  ELY ...\n"
     ]
    }
   ],
   "source": [
    "bugs, sources = generate_all_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix</th>\n",
       "      <th>text</th>\n",
       "      <th>fixdate</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>project</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>query</th>\n",
       "      <th>fix_indexes</th>\n",
       "      <th>numFixes</th>\n",
       "      <th>vector</th>\n",
       "      <th>direct_sim</th>\n",
       "      <th>indirect_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[flat3map.java, testflat3map.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:02:11</td>\n",
       "      <td>Flat3  Map.  Entry.set  Value() overwrites oth...</td>\n",
       "      <td>Flat3  Map&amp;amp;apos;s  Entry objects will over...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat3  Map.  Entry.set  Value() overwrites oth...</td>\n",
       "      <td>[233, 436]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.54710054, 0.8093695, -1.1743436, 0.1350008...</td>\n",
       "      <td>[-0.09654778, -0.07379957, -0.061074868, -0.08...</td>\n",
       "      <td>[0.0, 0.0, 0.01401775038901416, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[testextendedproperties.java, extendedproperti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:44:33</td>\n",
       "      <td>Extended  Properties - field include should be...</td>\n",
       "      <td>The field \"include\" in  Extended  Properties i...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Extended  Properties - field include should be...</td>\n",
       "      <td>[292, 22]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.010263926, -0.29718, -0.04093454, -0.13734...</td>\n",
       "      <td>[0.10770507, 0.11548331, 0.121062756, 0.205946...</td>\n",
       "      <td>[0.0, 0.0, 0.0269814923959674, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[testlistutils.java, testcollectionutils.java,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-18 19:01:22</td>\n",
       "      <td>Collection  Utils remove  All is actually reta...</td>\n",
       "      <td>The remove  All(  Collection collection,  Coll...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Collection  Utils remove  All is actually reta...</td>\n",
       "      <td>[303, 288, 15]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.01646587, -0.16084479, -0.042548787, -0.062...</td>\n",
       "      <td>[0.04446762, 0.14768608, 0.14675924, 0.10587, ...</td>\n",
       "      <td>[0.0, 0.0, 0.02720463365129317, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[flat3map.java, testflat3map.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-20 14:11:54</td>\n",
       "      <td>Flat3  Map.remove() does not return the correc...</td>\n",
       "      <td>Flat3  Map m = new  Flat3  Map(); m.put( new  ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat3  Map.remove() does not return the correc...</td>\n",
       "      <td>[233, 436]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.14817916, -0.18698174, 0.00082106725, -0.12...</td>\n",
       "      <td>[0.36616066, 0.06840743, 0.062879205, 0.113124...</td>\n",
       "      <td>[0.0, 0.0, 0.002627203000852418, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[fasttreemap.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-31 09:39:59</td>\n",
       "      <td>Fast  Tree  Map forgets the comparator</td>\n",
       "      <td>In line 359 and 582 of the current 3.2 release...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fast  Tree  Map forgets the comparatorIn line ...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.13191527, -0.18016613, 0.10219742, -0.1410...</td>\n",
       "      <td>[0.12645435, 0.21623495, 0.23732753, 0.1655188...</td>\n",
       "      <td>[0.0, 0.0, 0.02531724106223614, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>[ciphersuiteselector.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-01 13:52:37</td>\n",
       "      <td>Undertow  H  T  T  P  S listener offers no cip...</td>\n",
       "      <td>No cipher suites are available for handshake w...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Undertow  H  T  T  P  S listener offers no cip...</td>\n",
       "      <td>[10433]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5873729, -0.26671422, 0.26491788, 0.1084738...</td>\n",
       "      <td>[0.23647064, 0.23673111, -0.034009416, 0.29516...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>[abstractpermission.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-29 15:23:39</td>\n",
       "      <td>Missing null check in equals() method of  Abst...</td>\n",
       "      <td>There is missing null check in org.wildfly.sec...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing null check in equals() method of  Abst...</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.41595843, -0.3777295, 0.15903723, -0.05837...</td>\n",
       "      <td>[-0.040133074, -0.0024438687, 0.15373051, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>[elytronmessages.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-12 10:32:51</td>\n",
       "      <td>No log messages comming from  Elytron - group ...</td>\n",
       "      <td>Elytron is missing any log messages related to...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No log messages comming from  Elytron - group ...</td>\n",
       "      <td>[10457]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.10762189, 0.04025764, 0.188332, 0.17249116,...</td>\n",
       "      <td>[0.2632262, 0.21124604, 0.24380568, 0.19322138...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>[protocol.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-25 14:39:59</td>\n",
       "      <td>Elytron introduces  S  S  L  T  L  S protocol ...</td>\n",
       "      <td>L  I  S  T, \"description\" =&amp;gt; \"  The enabled...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elytron introduces  S  S  L  T  L  S protocol ...</td>\n",
       "      <td>[10447]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.066642396, -0.86785316, 0.024531504, 0.084...</td>\n",
       "      <td>[0.027853105, -0.041121133, -0.23069385, -0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>[elytronmessages.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-03 15:03:29</td>\n",
       "      <td>No log messages comming from  Elytron - permis...</td>\n",
       "      <td>Elytron is missing any log messages related to...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No log messages comming from  Elytron - permis...</td>\n",
       "      <td>[10457]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.105894886, -0.16939646, 0.21961711, 0.02162...</td>\n",
       "      <td>[0.24524426, 0.22394621, 0.26748505, 0.2634777...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fix text  \\\n",
       "0                    [flat3map.java, testflat3map.java]  NaN   \n",
       "1     [testextendedproperties.java, extendedproperti...  NaN   \n",
       "2     [testlistutils.java, testcollectionutils.java,...  NaN   \n",
       "3                    [flat3map.java, testflat3map.java]  NaN   \n",
       "4                                    [fasttreemap.java]  NaN   \n",
       "...                                                 ...  ...   \n",
       "1679                         [ciphersuiteselector.java]  NaN   \n",
       "1680                          [abstractpermission.java]  NaN   \n",
       "1681                             [elytronmessages.java]  NaN   \n",
       "1682                                    [protocol.java]  NaN   \n",
       "1683                             [elytronmessages.java]  NaN   \n",
       "\n",
       "                  fixdate                                            summary  \\\n",
       "0     2006-07-18 22:02:11  Flat3  Map.  Entry.set  Value() overwrites oth...   \n",
       "1     2006-07-18 22:44:33  Extended  Properties - field include should be...   \n",
       "2     2006-08-18 19:01:22  Collection  Utils remove  All is actually reta...   \n",
       "3     2007-08-20 14:11:54  Flat3  Map.remove() does not return the correc...   \n",
       "4     2007-08-31 09:39:59             Fast  Tree  Map forgets the comparator   \n",
       "...                   ...                                                ...   \n",
       "1679  2016-06-01 13:52:37  Undertow  H  T  T  P  S listener offers no cip...   \n",
       "1680  2016-07-29 15:23:39  Missing null check in equals() method of  Abst...   \n",
       "1681  2016-10-12 10:32:51  No log messages comming from  Elytron - group ...   \n",
       "1682  2016-10-25 14:39:59  Elytron introduces  S  S  L  T  L  S protocol ...   \n",
       "1683  2016-11-03 15:03:29  No log messages comming from  Elytron - permis...   \n",
       "\n",
       "                                            description      project  \\\n",
       "0     Flat3  Map&amp;apos;s  Entry objects will over...  COLLECTIONS   \n",
       "1     The field \"include\" in  Extended  Properties i...  COLLECTIONS   \n",
       "2     The remove  All(  Collection collection,  Coll...  COLLECTIONS   \n",
       "3     Flat3  Map m = new  Flat3  Map(); m.put( new  ...  COLLECTIONS   \n",
       "4     In line 359 and 582 of the current 3.2 release...  COLLECTIONS   \n",
       "...                                                 ...          ...   \n",
       "1679  No cipher suites are available for handshake w...          ELY   \n",
       "1680  There is missing null check in org.wildfly.sec...          ELY   \n",
       "1681  Elytron is missing any log messages related to...          ELY   \n",
       "1682  L  I  S  T, \"description\" =&gt; \"  The enabled...          ELY   \n",
       "1683  Elytron is missing any log messages related to...          ELY   \n",
       "\n",
       "      average_precision                                              query  \\\n",
       "0                   0.0  Flat3  Map.  Entry.set  Value() overwrites oth...   \n",
       "1                   0.0  Extended  Properties - field include should be...   \n",
       "2                   0.0  Collection  Utils remove  All is actually reta...   \n",
       "3                   0.0  Flat3  Map.remove() does not return the correc...   \n",
       "4                   0.0  Fast  Tree  Map forgets the comparatorIn line ...   \n",
       "...                 ...                                                ...   \n",
       "1679                0.0  Undertow  H  T  T  P  S listener offers no cip...   \n",
       "1680                0.0  Missing null check in equals() method of  Abst...   \n",
       "1681                0.0  No log messages comming from  Elytron - group ...   \n",
       "1682                0.0  Elytron introduces  S  S  L  T  L  S protocol ...   \n",
       "1683                0.0  No log messages comming from  Elytron - permis...   \n",
       "\n",
       "         fix_indexes  numFixes  \\\n",
       "0         [233, 436]         2   \n",
       "1          [292, 22]         2   \n",
       "2     [303, 288, 15]         3   \n",
       "3         [233, 436]         2   \n",
       "4               [27]         1   \n",
       "...              ...       ...   \n",
       "1679         [10433]         1   \n",
       "1680            [-1]         1   \n",
       "1681         [10457]         1   \n",
       "1682         [10447]         1   \n",
       "1683         [10457]         1   \n",
       "\n",
       "                                                 vector  \\\n",
       "0     [-0.54710054, 0.8093695, -1.1743436, 0.1350008...   \n",
       "1     [-0.010263926, -0.29718, -0.04093454, -0.13734...   \n",
       "2     [0.01646587, -0.16084479, -0.042548787, -0.062...   \n",
       "3     [0.14817916, -0.18698174, 0.00082106725, -0.12...   \n",
       "4     [-0.13191527, -0.18016613, 0.10219742, -0.1410...   \n",
       "...                                                 ...   \n",
       "1679  [0.5873729, -0.26671422, 0.26491788, 0.1084738...   \n",
       "1680  [-0.41595843, -0.3777295, 0.15903723, -0.05837...   \n",
       "1681  [0.10762189, 0.04025764, 0.188332, 0.17249116,...   \n",
       "1682  [-0.066642396, -0.86785316, 0.024531504, 0.084...   \n",
       "1683  [0.105894886, -0.16939646, 0.21961711, 0.02162...   \n",
       "\n",
       "                                             direct_sim  \\\n",
       "0     [-0.09654778, -0.07379957, -0.061074868, -0.08...   \n",
       "1     [0.10770507, 0.11548331, 0.121062756, 0.205946...   \n",
       "2     [0.04446762, 0.14768608, 0.14675924, 0.10587, ...   \n",
       "3     [0.36616066, 0.06840743, 0.062879205, 0.113124...   \n",
       "4     [0.12645435, 0.21623495, 0.23732753, 0.1655188...   \n",
       "...                                                 ...   \n",
       "1679  [0.23647064, 0.23673111, -0.034009416, 0.29516...   \n",
       "1680  [-0.040133074, -0.0024438687, 0.15373051, 0.02...   \n",
       "1681  [0.2632262, 0.21124604, 0.24380568, 0.19322138...   \n",
       "1682  [0.027853105, -0.041121133, -0.23069385, -0.03...   \n",
       "1683  [0.24524426, 0.22394621, 0.26748505, 0.2634777...   \n",
       "\n",
       "                                           indirect_sim  \n",
       "0     [0.0, 0.0, 0.01401775038901416, 0.0, 0.0, 0.0,...  \n",
       "1     [0.0, 0.0, 0.0269814923959674, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.02720463365129317, 0.0, 0.0, 0.0,...  \n",
       "3     [0.0, 0.0, 0.002627203000852418, 0.0, 0.0, 0.0...  \n",
       "4     [0.0, 0.0, 0.02531724106223614, 0.0, 0.0, 0.0,...  \n",
       "...                                                 ...  \n",
       "1679  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231...  \n",
       "1680  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146...  \n",
       "1681  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199...  \n",
       "1682  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132...  \n",
       "1683  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239...  \n",
       "\n",
       "[1684 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>unprocessed_code</th>\n",
       "      <th>project</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arraystack.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[0.6373648, 0.36343274, -0.21556364, 0.0261671...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[0.39248475, 0.9095622, -0.31791908, -0.447419...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagutils.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[-0.3806162, 0.014073659, 0.83630836, 0.206107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beanmap.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[-0.018915145, -0.20437856, 0.5265517, -0.2119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bidimap.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>[0.4636378, 0.3857351, -0.26127335, -0.1524405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>package-info.java</td>\n",
       "      <td>J  Boss,  Home of  Professional  Open  Source....</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[-0.09667181, -0.21859899, -0.253523, -0.35537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10457</th>\n",
       "      <td>elytronmessages.java</td>\n",
       "      <td>J  Boss,  Home of  Professional  Open  Source....</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[0.431815, -0.65128237, 0.6918912, -0.583043, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10458</th>\n",
       "      <td>testpermissionactions.java</td>\n",
       "      <td>J  Boss,  Home of  Professional  Open  Source....</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[-0.8184448, 0.2443168, 0.14690226, -0.8504981...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10459</th>\n",
       "      <td>teststackinspector.java</td>\n",
       "      <td>J  Boss,  Home of  Professional  Open  Source....</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[0.110203765, -0.09885522, -0.17536747, 0.0646...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10460</th>\n",
       "      <td>mechanismdatabasetest.java</td>\n",
       "      <td>J  Boss,  Home of  Professional  Open  Source....</td>\n",
       "      <td>ELY</td>\n",
       "      <td>[1.1933626, -1.3217556, 0.4555656, -0.14391084...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10461 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0                 arraystack.java   \n",
       "1                        bag.java   \n",
       "2                   bagutils.java   \n",
       "3                    beanmap.java   \n",
       "4                    bidimap.java   \n",
       "...                           ...   \n",
       "10456           package-info.java   \n",
       "10457        elytronmessages.java   \n",
       "10458  testpermissionactions.java   \n",
       "10459     teststackinspector.java   \n",
       "10460  mechanismdatabasetest.java   \n",
       "\n",
       "                                        unprocessed_code      project  \\\n",
       "0      Licensed to the  Apache  Software  Foundation ...  COLLECTIONS   \n",
       "1      Licensed to the  Apache  Software  Foundation ...  COLLECTIONS   \n",
       "2      Licensed to the  Apache  Software  Foundation ...  COLLECTIONS   \n",
       "3      Licensed to the  Apache  Software  Foundation ...  COLLECTIONS   \n",
       "4      Licensed to the  Apache  Software  Foundation ...  COLLECTIONS   \n",
       "...                                                  ...          ...   \n",
       "10456  J  Boss,  Home of  Professional  Open  Source....          ELY   \n",
       "10457  J  Boss,  Home of  Professional  Open  Source....          ELY   \n",
       "10458  J  Boss,  Home of  Professional  Open  Source....          ELY   \n",
       "10459  J  Boss,  Home of  Professional  Open  Source....          ELY   \n",
       "10460  J  Boss,  Home of  Professional  Open  Source....          ELY   \n",
       "\n",
       "                                                  vector  \n",
       "0      [0.6373648, 0.36343274, -0.21556364, 0.0261671...  \n",
       "1      [0.39248475, 0.9095622, -0.31791908, -0.447419...  \n",
       "2      [-0.3806162, 0.014073659, 0.83630836, 0.206107...  \n",
       "3      [-0.018915145, -0.20437856, 0.5265517, -0.2119...  \n",
       "4      [0.4636378, 0.3857351, -0.26127335, -0.1524405...  \n",
       "...                                                  ...  \n",
       "10456  [-0.09667181, -0.21859899, -0.253523, -0.35537...  \n",
       "10457  [0.431815, -0.65128237, 0.6918912, -0.583043, ...  \n",
       "10458  [-0.8184448, 0.2443168, 0.14690226, -0.8504981...  \n",
       "10459  [0.110203765, -0.09885522, -0.17536747, 0.0646...  \n",
       "10460  [1.1933626, -1.3217556, 0.4555656, -0.14391084...  \n",
       "\n",
       "[10461 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bugs)\n",
    "display(sources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
