{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>unprocessed_code</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "1  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "2  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "3  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "4  \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "\n",
       "                                    unprocessed_code      project  \n",
       "0  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "1  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "2  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "3  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "4  /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix</th>\n",
       "      <th>text</th>\n",
       "      <th>fixdate</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>project</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:02:11</td>\n",
       "      <td>Flat3Map.Entry.setValue() overwrites other Ent...</td>\n",
       "      <td>Flat3Map&amp;amp;apos;s Entry objects will overwri...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>[org.apache.commons.collections.testextendedpr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:44:33</td>\n",
       "      <td>ExtendedProperties - field include should be n...</td>\n",
       "      <td>The field \"include\" in ExtendedProperties is c...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>[org.apache.commons.collections.testlistutils....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-18 19:01:22</td>\n",
       "      <td>CollectionUtils removeAll is actually retainAll</td>\n",
       "      <td>The removeAll(Collection collection, Collectio...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-20 14:11:54</td>\n",
       "      <td>Flat3Map.remove() does not return the correct ...</td>\n",
       "      <td>final Flat3Map m = new Flat3Map();\\n  ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[org.apache.commons.collections.fasttreemap.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-31 09:39:59</td>\n",
       "      <td>FastTreeMap forgets the comparator</td>\n",
       "      <td>In line 359 and 582 of the current 3.2 release...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fix text  \\\n",
       "id                                                            \n",
       "217  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "214  [org.apache.commons.collections.testextendedpr...  NaN   \n",
       "222  [org.apache.commons.collections.testlistutils....  NaN   \n",
       "261  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "264  [org.apache.commons.collections.fasttreemap.java]  NaN   \n",
       "\n",
       "                 fixdate                                            summary  \\\n",
       "id                                                                            \n",
       "217  2006-07-18 22:02:11  Flat3Map.Entry.setValue() overwrites other Ent...   \n",
       "214  2006-07-18 22:44:33  ExtendedProperties - field include should be n...   \n",
       "222  2006-08-18 19:01:22    CollectionUtils removeAll is actually retainAll   \n",
       "261  2007-08-20 14:11:54  Flat3Map.remove() does not return the correct ...   \n",
       "264  2007-08-31 09:39:59                 FastTreeMap forgets the comparator   \n",
       "\n",
       "                                           description      project  \\\n",
       "id                                                                    \n",
       "217  Flat3Map&amp;apos;s Entry objects will overwri...  COLLECTIONS   \n",
       "214  The field \"include\" in ExtendedProperties is c...  COLLECTIONS   \n",
       "222  The removeAll(Collection collection, Collectio...  COLLECTIONS   \n",
       "261          final Flat3Map m = new Flat3Map();\\n  ...  COLLECTIONS   \n",
       "264  In line 359 and 582 of the current 3.2 release...  COLLECTIONS   \n",
       "\n",
       "     average_precision  \n",
       "id                      \n",
       "217                0.0  \n",
       "214                0.0  \n",
       "222                0.0  \n",
       "261                0.0  \n",
       "264                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('Output/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('Output/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "\n",
    "display(all_projects_source_codes.head())\n",
    "display(all_projects_bugreports.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing New Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove next line characters:\n",
    "def remove_new_lines(text):\n",
    "    text = str(text)\n",
    "    COMBINE_WHITE_SPACE = re.compile(r\"(?a:\\s+)\")\n",
    "    text = COMBINE_WHITE_SPACE.sub(' ', text)\n",
    "    return text.replace('*', '').replace('/', '').replace('\\\\','')\n",
    "    \n",
    "# clean up the various white space and remove some *\n",
    "def clean_new_lines_source_code(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(remove_new_lines)\n",
    "    return df\n",
    "\n",
    "# clean up the description and summary, they will both be used for the query\n",
    "def clean_new_lines_bug_report(df):\n",
    "    df.summary = df.summary.apply(remove_new_lines)\n",
    "    df['description'] = df['description'].astype('|U')\n",
    "    df.description = df.description.apply(remove_new_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes file path to be just the filename + extension for source code files\n",
    "def clean_sc_file(x):\n",
    "    file = x.split(\"\\\\\")\n",
    "    return ''.join(file[-1:])\n",
    "\n",
    "# changes file path to be just the filename + extension for bug report fixes \n",
    "def clean_bug_file(x):\n",
    "    fixes = []\n",
    "\n",
    "    for file in x:\n",
    "        file = file.split(\".\")\n",
    "        file = '.'.join(file[-2:])\n",
    "        fixes.append(file)\n",
    "    return fixes\n",
    "\n",
    "\n",
    "def clean_sc_filepath(df):\n",
    "    df.filename = df.filename.map(clean_sc_file)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_bug_filepath(df):\n",
    "    df['fix'] = df['fix'].map(clean_bug_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Composite Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting composite words\n",
    "#splits using camlecase syntax\n",
    "def findCompositeWords(s):\n",
    "    return ' '.join(re.findall('[A-Z][^A-Z]*', s))   \n",
    "\n",
    "\n",
    "def clean_composite_source_code(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(findCompositeWords)\n",
    "    return df\n",
    "\n",
    "def clean_composite_bug_report(df):\n",
    "    df.summary = df.summary.apply(findCompositeWords)\n",
    "    df.description = df.description.apply(findCompositeWords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove fixes that can't be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look through the src data frame to find where the fix is. \n",
    "def get_fix_indexes(bug, src):\n",
    "    fix_list = list()\n",
    "    for fixes in bug[\"fix\"]:\n",
    "        fix_sub=list()\n",
    "        for fix in fixes:\n",
    "            df = src[src[\"filename\"].str.match(fix)]\n",
    "            if(df.shape[0] != 0):\n",
    "                fix_sub.append(df.index[0])\n",
    "            else:\n",
    "                fix_sub.append(-1)\n",
    "        fix_list.append(fix_sub)\n",
    "    # this is a list of the indexes of the file where the fix was located\n",
    "    return fix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFixesNotFound(bug, src):\n",
    "    bug[\"fix_indexes\"] = get_fix_indexes(bug, src)\n",
    "    fixes = bug.fix.tolist()\n",
    "    fix_indexes = bug.fix_indexes.tolist()\n",
    "    fixes_return = []\n",
    "    fixes_indexes_return = []\n",
    "    for i in range(len(fixes)):\n",
    "        fixes_temp = []\n",
    "        indexes_temp = []\n",
    "        for l in range(len(fix_indexes[i])):\n",
    "            if fix_indexes[i][l] != -1:           \n",
    "                fixes_temp.append(fixes[i][l])\n",
    "                indexes_temp.append(fix_indexes[i][l])\n",
    "        if len(fixes_temp) == 0:\n",
    "            fixes_return.append(np.nan)\n",
    "            fixes_indexes_return.append(np.nan)\n",
    "        else:\n",
    "            fixes_return.append(fixes_temp)\n",
    "            fixes_indexes_return.append(indexes_temp)\n",
    "#         print(fixes_return)\n",
    "#         print(fixes_indexes_return)\n",
    "    bug['fix'] = fixes_return\n",
    "    bug['fix_indexes'] = fixes_indexes_return \n",
    "    \n",
    "    return bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the unprocessed code column\n",
    "def clean_source_df(df):\n",
    "    # clean up the new lines\n",
    "    df = clean_new_lines_source_code(df)\n",
    "    # clean up composite words\n",
    "    df = clean_composite_source_code(df)\n",
    "    # clean filepaths\n",
    "    df = clean_sc_filepath(df)\n",
    "    return df\n",
    "\n",
    "# add the summary and description together and clean the data\n",
    "def clean_combine_bug_df(df):\n",
    "    # clean up new lines\n",
    "    df = clean_new_lines_bug_report(df)\n",
    "    # clean composite words\n",
    "    df = clean_composite_bug_report(df)\n",
    "    # clean file path\n",
    "    df = clean_bug_filepath(df)\n",
    "    # combine summary and descriptions to create query\n",
    "    df[\"query\"] = df[\"summary\"] + df[\"description\"]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cleaning and Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_bugreports = all_projects_bugreports.dropna(axis=0, subset=['fix'], how='all')\n",
    "\n",
    "#  get clean versions of the dataframes\n",
    "sc_df = clean_source_df(all_projects_source_codes)\n",
    "br_df = clean_combine_bug_df(all_projects_bugreports)\n",
    "\n",
    "\n",
    "# remove fixes that aren't found\n",
    "br_df = removeFixesNotFound(br_df, sc_df)\n",
    "br_df = br_df.dropna(axis=0, subset=['fix','fix_indexes'], how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the clean DFs as pickle files to prevent having to clean them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df.to_pickle(\"./Output/cleanSource.pickle\")\n",
    "br_df.to_pickle(\"./Output/cleanBugs.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining stop words, keywords and operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the Java key words to the stop words\n",
    "java_keywords = [\"abstract\", \"assert**\",\"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"enum****\" \"extends\", \"final\", \"finally\", \"for\", \"goto\",\"goto*\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\",\"interface\", \"long\", \"native\", \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp**\",\"strictfp\", \"super\", \"switch\", \"synchornized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\"]\n",
    "java_operators = [\"+\", \"-\", \"*\", \"/\", \"%\", \"+=\", \"-=\", \"*=\", \"/=\", \"++\", \"--\", \"==\", \"!=\", \"<\", \">\", \"<=\", \">=\", \".\", \"[\", \"]\", \"(\",\")\", \"!\", \"~\",\"instanceof\", \"<<\", \">>\", \">>>\", \"&\", \"^\", \"|\", \"&&\", \"||\", \"?\", \":\", \"^=\", \"%=\", \"<<=\", \">>=\", \">>>=\", \"&=\"]\n",
    "stop = java_keywords + java_operators\n",
    "#contains english stop words, java keywords and java operators\n",
    "STOP_WORDS = ENGLISH_STOP_WORDS.union(stop)\n",
    "\n",
    "# remove the stem and stop words\n",
    "# takes in an array of strings returns an array of strings\n",
    "def stem_stop(text):\n",
    "    stemmer = PorterStemmer()   #\"english\"\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in STOP_WORDS]\n",
    "    text = list(map(lambda x: stemmer.stem(x), text))\n",
    "    text = ' '.join(text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Series with all the source code files and all the bug reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series with all the source code and all the\n",
    "sc_df.reset_index(drop=True, inplace=True)\n",
    "training_src = sc_df.iloc[:, 0:3].copy()\n",
    "training_src.columns = ['filename', 'query', 'project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bugs = br_df[[\"query\", \"project\"]].copy()\n",
    "training_bugs['filename'] = 'bug'\n",
    "training_bugs.reset_index(drop=True, inplace=True)\n",
    "training_bugs = training_bugs[['filename', 'query','project']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>query</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arraystack.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagutils.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beanmap.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bidimap.java</td>\n",
       "      <td>Licensed to the  Apache  Software  Foundation ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12140</th>\n",
       "      <td>bug</td>\n",
       "      <td>Undertow  H T T P S listener offers no cipher ...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12141</th>\n",
       "      <td>bug</td>\n",
       "      <td>Missing null check in equals() method of  Abst...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12142</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messages comming from  Elytron - group ...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12143</th>\n",
       "      <td>bug</td>\n",
       "      <td>Elytron introduces  S S L T L S protocol const...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12144</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messages comming from  Elytron - permis...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                              query  \\\n",
       "0      arraystack.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "1             bag.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "2        bagutils.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "3         beanmap.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "4         bidimap.java  Licensed to the  Apache  Software  Foundation ...   \n",
       "...                ...                                                ...   \n",
       "12140              bug  Undertow  H T T P S listener offers no cipher ...   \n",
       "12141              bug  Missing null check in equals() method of  Abst...   \n",
       "12142              bug  No log messages comming from  Elytron - group ...   \n",
       "12143              bug  Elytron introduces  S S L T L S protocol const...   \n",
       "12144              bug  No log messages comming from  Elytron - permis...   \n",
       "\n",
       "           project  \n",
       "0      COLLECTIONS  \n",
       "1      COLLECTIONS  \n",
       "2      COLLECTIONS  \n",
       "3      COLLECTIONS  \n",
       "4      COLLECTIONS  \n",
       "...            ...  \n",
       "12140          ELY  \n",
       "12141          ELY  \n",
       "12142          ELY  \n",
       "12143          ELY  \n",
       "12144          ELY  \n",
       "\n",
       "[12145 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.concat([training_src, training_bugs], ignore_index=True)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of stop words and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>query</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arraystack.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagutils.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beanmap.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bidimap.java</td>\n",
       "      <td>licens apach softwar foundat A S F) contributo...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12140</th>\n",
       "      <td>bug</td>\n",
       "      <td>undertow H T T P S listen offer cipher suit D ...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12141</th>\n",
       "      <td>bug</td>\n",
       "      <td>miss null check equals() method abstract permi...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12142</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messag com elytron group assignmentelyt...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12143</th>\n",
       "      <td>bug</td>\n",
       "      <td>elytron introduc S S L T L S protocol constrai...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12144</th>\n",
       "      <td>bug</td>\n",
       "      <td>No log messag com elytron permiss assignmentel...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                              query  \\\n",
       "0      arraystack.java  licens apach softwar foundat A S F) contributo...   \n",
       "1             bag.java  licens apach softwar foundat A S F) contributo...   \n",
       "2        bagutils.java  licens apach softwar foundat A S F) contributo...   \n",
       "3         beanmap.java  licens apach softwar foundat A S F) contributo...   \n",
       "4         bidimap.java  licens apach softwar foundat A S F) contributo...   \n",
       "...                ...                                                ...   \n",
       "12140              bug  undertow H T T P S listen offer cipher suit D ...   \n",
       "12141              bug  miss null check equals() method abstract permi...   \n",
       "12142              bug  No log messag com elytron group assignmentelyt...   \n",
       "12143              bug  elytron introduc S S L T L S protocol constrai...   \n",
       "12144              bug  No log messag com elytron permiss assignmentel...   \n",
       "\n",
       "           project  \n",
       "0      COLLECTIONS  \n",
       "1      COLLECTIONS  \n",
       "2      COLLECTIONS  \n",
       "3      COLLECTIONS  \n",
       "4      COLLECTIONS  \n",
       "...            ...  \n",
       "12140          ELY  \n",
       "12141          ELY  \n",
       "12142          ELY  \n",
       "12143          ELY  \n",
       "12144          ELY  \n",
       "\n",
       "[12145 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['query'] = training_data['query'].map(stem_stop)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now start training the Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min 41s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# get the tagged documents for the doc2vec model\n",
    "training_docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(list(training_data['query']))]\n",
    "training_docs\n",
    "\n",
    "# initialize model\n",
    "# vector_size = dimensionality of the feature vectors (25, 100, 200)\n",
    "# window = the max distance bweteeen the predicted word and context words \"TUNE\"\n",
    "# alpha = the initial learning rate (says that this will drop as training progresses)\n",
    "# seed = for reproducibility (MAKE SURE IT WORKS) \"TUNE\"  [says you need 1 worker for reproducibility]\n",
    "# min_count = ignore all words with a frequency lower than this\n",
    "# max_vocab size = limit RAM during vocab building every 1 million words needs 1GB of RAM\n",
    "# workers = number of worker threads used to train. \n",
    "# epochs = number of epochs over the corpus (10-20??)\n",
    "\n",
    "# time the single run\n",
    "%timeit -n1 -r1 doc_model = Doc2Vec(training_docs, vector_size=25, window=3, alpha=0.05, min_count=1, seed=42, workers=1, epochs=20)\n",
    "\n",
    "# build vocabulary\n",
    "\n",
    "# train model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6min 6s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 doc_model2 = Doc2Vec(training_docs, vector_size=100, window=3, alpha=0.05, min_count=1, seed=42, workers=1, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6min 34s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 doc_model3 = Doc2Vec(training_docs, vector_size=200, window=3, alpha=0.05, min_count=1, seed=42, workers=1, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 10s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 doc_model4 = Doc2Vec(training_docs, vector_size=200, window=3, alpha=0.05, min_count=1, seed=42, workers=4, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 doc_model5 = Doc2Vec(training_docs, vector_size=25, window=3, alpha=0.05, min_count=1, seed=42, workers=1, epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
