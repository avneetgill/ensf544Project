{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 \n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load the pickle data into dataframes from the Output folder one directory above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** All Bug Reports are Loaded. ***\n*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   fix text  \\\n",
       "id                                                            \n",
       "217  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "214  [org.apache.commons.collections.testextendedpr...  NaN   \n",
       "222  [org.apache.commons.collections.testlistutils....  NaN   \n",
       "261  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "264  [org.apache.commons.collections.fasttreemap.java]  NaN   \n",
       "..                                                 ...  ...   \n",
       "692  [org.wildfly.security.auth.realm.legacypropert...  NaN   \n",
       "691  [org.wildfly.security.auth.realm.legacypropert...  NaN   \n",
       "637  [org.wildfly.security.auth.server.serverauthen...  NaN   \n",
       "757  [org.wildfly.security.ssl.sslauthenticationtes...  NaN   \n",
       "808  [org.wildfly.security.auth.client.elytronxmlpa...  NaN   \n",
       "\n",
       "                 fixdate                                            summary  \\\n",
       "id                                                                            \n",
       "217  2006-07-18 22:02:11  Flat3Map.Entry.setValue() overwrites other Ent...   \n",
       "214  2006-07-18 22:44:33  ExtendedProperties - field include should be n...   \n",
       "222  2006-08-18 19:01:22    CollectionUtils removeAll is actually retainAll   \n",
       "261  2007-08-20 14:11:54  Flat3Map.remove() does not return the correct ...   \n",
       "264  2007-08-31 09:39:59                 FastTreeMap forgets the comparator   \n",
       "..                   ...                                                ...   \n",
       "692  2016-11-02 09:35:48  Add tests for special chars in LegacyPropertie...   \n",
       "691  2016-11-02 09:36:13  Elytron properties-realm is not compatible wit...   \n",
       "637  2016-11-03 15:03:29  No log messages comming from Elytron - permiss...   \n",
       "757  2016-11-21 09:24:47  Don&apos;t use String toUpperCase/toLowerCase ...   \n",
       "808  2016-12-02 17:08:15                 XML Parsing Deferred into Function   \n",
       "\n",
       "                                           description      project  \\\n",
       "id                                                                    \n",
       "217  Flat3Map&amp;apos;s Entry objects will overwri...  COLLECTIONS   \n",
       "214  The field \"include\" in ExtendedProperties is c...  COLLECTIONS   \n",
       "222  The removeAll(Collection collection, Collectio...  COLLECTIONS   \n",
       "261          final Flat3Map m = new Flat3Map();\\n  ...  COLLECTIONS   \n",
       "264  In line 359 and 582 of the current 3.2 release...  COLLECTIONS   \n",
       "..                                                 ...          ...   \n",
       "692  Add tests for issue https://issues.jboss.org/b...          ELY   \n",
       "691  When users properties file (e.g. mgmt-users.pr...          ELY   \n",
       "637  Elytron is missing any log messages related to...          ELY   \n",
       "757  The String.toUpperCase() and String.toLowerCas...          ELY   \n",
       "808  e.g.\\n\\n\\n\\n\\n\\n\\n                    case \"cl...          ELY   \n",
       "\n",
       "     average_precision  \n",
       "id                      \n",
       "217                0.0  \n",
       "214                0.0  \n",
       "222                0.0  \n",
       "261                0.0  \n",
       "264                0.0  \n",
       "..                 ...  \n",
       "692                0.0  \n",
       "691                0.0  \n",
       "637                0.0  \n",
       "757                0.0  \n",
       "808                0.0  \n",
       "\n",
       "[1858 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fix</th>\n      <th>text</th>\n      <th>fixdate</th>\n      <th>summary</th>\n      <th>description</th>\n      <th>project</th>\n      <th>average_precision</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>217</th>\n      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n      <td>NaN</td>\n      <td>2006-07-18 22:02:11</td>\n      <td>Flat3Map.Entry.setValue() overwrites other Ent...</td>\n      <td>Flat3Map&amp;amp;apos;s Entry objects will overwri...</td>\n      <td>COLLECTIONS</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>[org.apache.commons.collections.testextendedpr...</td>\n      <td>NaN</td>\n      <td>2006-07-18 22:44:33</td>\n      <td>ExtendedProperties - field include should be n...</td>\n      <td>The field \"include\" in ExtendedProperties is c...</td>\n      <td>COLLECTIONS</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>222</th>\n      <td>[org.apache.commons.collections.testlistutils....</td>\n      <td>NaN</td>\n      <td>2006-08-18 19:01:22</td>\n      <td>CollectionUtils removeAll is actually retainAll</td>\n      <td>The removeAll(Collection collection, Collectio...</td>\n      <td>COLLECTIONS</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n      <td>NaN</td>\n      <td>2007-08-20 14:11:54</td>\n      <td>Flat3Map.remove() does not return the correct ...</td>\n      <td>final Flat3Map m = new Flat3Map();\\n  ...</td>\n      <td>COLLECTIONS</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>[org.apache.commons.collections.fasttreemap.java]</td>\n      <td>NaN</td>\n      <td>2007-08-31 09:39:59</td>\n      <td>FastTreeMap forgets the comparator</td>\n      <td>In line 359 and 582 of the current 3.2 release...</td>\n      <td>COLLECTIONS</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>692</th>\n      <td>[org.wildfly.security.auth.realm.legacypropert...</td>\n      <td>NaN</td>\n      <td>2016-11-02 09:35:48</td>\n      <td>Add tests for special chars in LegacyPropertie...</td>\n      <td>Add tests for issue https://issues.jboss.org/b...</td>\n      <td>ELY</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>691</th>\n      <td>[org.wildfly.security.auth.realm.legacypropert...</td>\n      <td>NaN</td>\n      <td>2016-11-02 09:36:13</td>\n      <td>Elytron properties-realm is not compatible wit...</td>\n      <td>When users properties file (e.g. mgmt-users.pr...</td>\n      <td>ELY</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>[org.wildfly.security.auth.server.serverauthen...</td>\n      <td>NaN</td>\n      <td>2016-11-03 15:03:29</td>\n      <td>No log messages comming from Elytron - permiss...</td>\n      <td>Elytron is missing any log messages related to...</td>\n      <td>ELY</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>757</th>\n      <td>[org.wildfly.security.ssl.sslauthenticationtes...</td>\n      <td>NaN</td>\n      <td>2016-11-21 09:24:47</td>\n      <td>Don&amp;apos;t use String toUpperCase/toLowerCase ...</td>\n      <td>The String.toUpperCase() and String.toLowerCas...</td>\n      <td>ELY</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>808</th>\n      <td>[org.wildfly.security.auth.client.elytronxmlpa...</td>\n      <td>NaN</td>\n      <td>2016-12-02 17:08:15</td>\n      <td>XML Parsing Deferred into Function</td>\n      <td>e.g.\\n\\n\\n\\n\\n\\n\\n                    case \"cl...</td>\n      <td>ELY</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1858 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('../Output/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('../Output/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "# display(all_projects_bugreports.iloc[0])\n",
    "# display(all_projects_source_codes.iloc[0].unprocessed_code)\n",
    "\n",
    "all_projects_bugreports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing composite varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove next line characters:\n",
    "def remove_new_lines(x):\n",
    "    return x.replace('\\n', '').replace('*', '').replace('/', '').replace('\\t','')\n",
    "\n",
    "def clean_new_lines(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(remove_new_lines)\n",
    "    return df\n",
    "\n",
    "# df = clean_new_lines(all_projects_source_codes)\n",
    "# df.iloc[0].unprocessed_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#splitting composite words\n",
    "def findCompositeWords(s):\n",
    "    return ' '.join(re.findall('[A-Z][^A-Z]*', s))   \n",
    "\n",
    "\n",
    "def clean_name_column(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(findCompositeWords)\n",
    "    return df\n",
    "\n",
    "# df = clean_name_column(all_projects_source_codes)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put Kelvin's key word cleaning above this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "# add the Java key words to the stop words\n",
    "\n",
    "# TODO we need to add the operators in here too\n",
    "java_keywords = [\"abstract\", \"assert**\",\"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"enum****\" \"extends\", \"final\", \"finally\", \"for\", \"goto\",\"goto*\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\",\"interface\", \"long\", \"native\", \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp**\",\"strictfp\", \"super\", \"switch\", \"synchornized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\"]\n",
    "STOP_WORDS = ENGLISH_STOP_WORDS.union(java_keywords)\n",
    "# STOP_WORDS\n",
    "\n",
    "\n",
    "#vect = CountVectorizer(min_df = 5, stop_words = stop, analyzer = 'word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start working on TF-IDF and Cosine similarity calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['COLLECTIONS' 'CONFIGURATION' 'IO' 'LANG' 'DATACMNS' 'DATAMONGO'\n 'DATAREST' 'LDAP' 'SEC' 'SOCIALFB' 'SPR' 'ELY']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ea742a7f89ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# get a list of the projects and their parent project\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mprojects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mcommons_projects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprojects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mspring_projects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprojects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# clean up the unprocessed code column\n",
    "def clean_source_code_list(sc_df):\n",
    "    sc_df = clean_new_lines(sc_df)\n",
    "    sc_df = clean_name_column(sc_df)\n",
    "    return sc_df\n",
    "\n",
    "# get clean versions of the dataframes\n",
    "sc_df = clean_source_code_list(all_projects_source_codes)\n",
    "\n",
    "# TODO figure out which we need from the bug report \n",
    "#           do we use summary or description or both?\n",
    "# bug_df = clean_source_code_list(all_projects_bugreports)\n",
    "\n",
    "\n",
    "# get a list of the projects and their parent project\n",
    "print(sc_df.project.unique())\n",
    "projects = sc_df.project.unique()\n",
    "commons_projects = projects[0:4]\n",
    "spring_projects = projects[4:11]\n",
    "wildfly_projects = projects[11]\n",
    "\n",
    "# group the data frames\n",
    "grouped_df = sc_df.groupby(sc_df.project)\n",
    "\n",
    "# example of getting a single data frame\n",
    "col_df = grouped_df.get_group(\"COLLECTIONS\")\n",
    "display(col_df)\n",
    "\n",
    "config_df = grouped_df.get_group(commons_projects[1])\n",
    "ely_df = grouped_df.get_group(wildfly_projects)\n",
    "ldap_df = grouped_df.get_group(spring_projects[3])\n",
    "\n",
    "print(config_df.iloc[0].filename)\n",
    "print(col_df.iloc[0].filename)\n",
    "print(ely_df.iloc[0].filename)\n",
    "print(ldap_df.iloc[0].filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_parent_df(group, names):\n",
    "    result = pd.DataFrame\n",
    "    temp = []\n",
    "    for name in names:\n",
    "        temp.append(group.get_group(name))\n",
    "    \n",
    "    result = pd.concate(temp, ignore_index = true)    \n",
    "    return result\n",
    "\n",
    "# don't know if we are looking at these groups OR each of the projects individually\n",
    "commons_df = gen_parent_df(grouped_df, commons_projects)\n",
    "sprint_df = gen_parent_df(grouped_df, spring_projects)\n",
    "wildfly_df = gen_parent_df(grouped_df, wildfly_projects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def calculate_similarity(source_code, bug):\n",
    "    cosSim = cosine_similarity(bug, source_code).flatten()\n",
    "    return cosSim\n",
    "\n",
    "# fit the vectorizer and transform data\n",
    "def transform_data(source_code_data, query_data):\n",
    "    # DO WE SET min_df?  default normalization is l2\n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\").fit(source_code_data)\n",
    "    X = vect.transform(source_code_data)\n",
    "    y = vect.transform(query_data)\n",
    "    similarity = calculate_similarity(X,y)\n",
    "    return X, y, similarity\n",
    "\n",
    "# remove the stem and stop words\n",
    "def stem_stop(text):\n",
    "    stemmer =PorterStemmer(\"english\")\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in STOP_WORDS]\n",
    "    text = list(map(lambda x: stemmer.stem(x), text))\n",
    "    text = ' '.join(text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# first stem and remove stop words from the data frames column\n",
    "# example \n",
    "# TODO don't know if we look through all projects or look at them individually\n",
    "# source_code_df['unprocessed_code'] = source_code_df['unprocessed_code'].map(stem_stop)\n",
    "# bug_df['unprocessed_code'] = bug_df['unprocessed_code'].map(stem_stop)\n",
    "\n",
    "# then get the dataframe column you want to pass as source_code_data and as the query_data(bug)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}