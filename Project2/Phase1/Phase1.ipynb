{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 \n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load the pickle data into dataframes from the Output folder one directory above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fix                  [org.apache.commons.collections.map.flat3map.j...\n",
       "text                                                               NaN\n",
       "fixdate                                            2006-07-18 22:02:11\n",
       "summary              Flat3Map.Entry.setValue() overwrites other Ent...\n",
       "description          Flat3Map&amp;apos;s Entry objects will overwri...\n",
       "project                                                    COLLECTIONS\n",
       "average_precision                                                    0\n",
       "Name: 217, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/*\\n *  Licensed to the Apache Software Foundation (ASF) under one or more\\n *  contributor license agreements.  See the NOTICE file distributed with\\n *  this work for additional information regarding copyright ownership.\\n *  The ASF licenses this file to You under the Apache License, Version 2.0\\n *  (the \"License\"); you may not use this file except in compliance with\\n *  the License.  You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n *  Unless required by applicable law or agreed to in writing, software\\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n *  See the License for the specific language governing permissions and\\n *  limitations under the License.\\n */\\npackage org.apache.commons.collections;\\n\\nimport java.util.ArrayList;\\nimport java.util.EmptyStackException;\\n\\n/**\\n * An implementation of the {@link java.util.Stack} API that is based on an\\n * <code>ArrayList</code> instead of a <code>Vector</code>, so it is not\\n * synchronized to protect against multi-threaded access.  The implementation\\n * is therefore operates faster in environments where you do not need to\\n * worry about multiple thread contention.\\n * <p>\\n * The removal order of an <code>ArrayStack</code> is based on insertion \\n * order: The most recently added element is removed first.  The iteration\\n * order is <i>not</i> the same as the removal order.  The iterator returns\\n * elements from the bottom up, whereas the {@link #remove()} method removes\\n * them from the top down.\\n * <p>\\n * Unlike <code>Stack</code>, <code>ArrayStack</code> accepts null entries.\\n *\\n * @see java.util.Stack\\n * @since Commons Collections 1.0\\n * @version $Revision$ $Date$\\n * \\n * @author Craig R. McClanahan\\n * @author Paul Jack\\n * @author Stephen Colebourne\\n */\\npublic class ArrayStack extends ArrayList implements Buffer {\\n\\n    /** Ensure serialization compatibility */    \\n    private static final long serialVersionUID = 2130079159931574599L;\\n\\n    /**\\n     * Constructs a new empty <code>ArrayStack</code>. The initial size\\n     * is controlled by <code>ArrayList</code> and is currently 10.\\n     */\\n    public ArrayStack() {\\n        super();\\n    }\\n\\n    /**\\n     * Constructs a new empty <code>ArrayStack</code> with an initial size.\\n     * \\n     * @param initialSize  the initial size to use\\n     * @throws IllegalArgumentException  if the specified initial size\\n     *  is negative\\n     */\\n    public ArrayStack(int initialSize) {\\n        super(initialSize);\\n    }\\n\\n    /**\\n     * Return <code>true</code> if this stack is currently empty.\\n     * <p>\\n     * This method exists for compatibility with <code>java.util.Stack</code>.\\n     * New users of this class should use <code>isEmpty</code> instead.\\n     * \\n     * @return true if the stack is currently empty\\n     */\\n    public boolean empty() {\\n        return isEmpty();\\n    }\\n\\n    /**\\n     * Returns the top item off of this stack without removing it.\\n     *\\n     * @return the top item on the stack\\n     * @throws EmptyStackException  if the stack is empty\\n     */\\n    public Object peek() throws EmptyStackException {\\n        int n = size();\\n        if (n <= 0) {\\n            throw new EmptyStackException();\\n        } else {\\n            return get(n - 1);\\n        }\\n    }\\n\\n    /**\\n     * Returns the n\\'th item down (zero-relative) from the top of this\\n     * stack without removing it.\\n     *\\n     * @param n  the number of items down to go\\n     * @return the n\\'th item on the stack, zero relative\\n     * @throws EmptyStackException  if there are not enough items on the\\n     *  stack to satisfy this request\\n     */\\n    public Object peek(int n) throws EmptyStackException {\\n        int m = (size() - n) - 1;\\n        if (m < 0) {\\n            throw new EmptyStackException();\\n        } else {\\n            return get(m);\\n        }\\n    }\\n\\n    /**\\n     * Pops the top item off of this stack and return it.\\n     *\\n     * @return the top item on the stack\\n     * @throws EmptyStackException  if the stack is empty\\n     */\\n    public Object pop() throws EmptyStackException {\\n        int n = size();\\n        if (n <= 0) {\\n            throw new EmptyStackException();\\n        } else {\\n            return remove(n - 1);\\n        }\\n    }\\n\\n    /**\\n     * Pushes a new item onto the top of this stack. The pushed item is also\\n     * returned. This is equivalent to calling <code>add</code>.\\n     *\\n     * @param item  the item to be added\\n     * @return the item just pushed\\n     */\\n    public Object push(Object item) {\\n        add(item);\\n        return item;\\n    }\\n\\n    /**\\n     * Returns the one-based position of the distance from the top that the\\n     * specified object exists on this stack, where the top-most element is\\n     * considered to be at distance <code>1</code>.  If the object is not\\n     * present on the stack, return <code>-1</code> instead.  The\\n     * <code>equals()</code> method is used to compare to the items\\n     * in this stack.\\n     *\\n     * @param object  the object to be searched for\\n     * @return the 1-based depth into the stack of the object, or -1 if not found\\n     */\\n    public int search(Object object) {\\n        int i = size() - 1;        // Current index\\n        int n = 1;                 // Current distance\\n        while (i >= 0) {\\n            Object current = get(i);\\n            if ((object == null && current == null) ||\\n                (object != null && object.equals(current))) {\\n                return n;\\n            }\\n            i--;\\n            n++;\\n        }\\n        return -1;\\n    }\\n\\n    /**\\n     * Returns the element on the top of the stack.\\n     *\\n     * @return the element on the top of the stack\\n     * @throws BufferUnderflowException  if the stack is empty\\n     */\\n    public Object get() {\\n        int size = size();\\n        if (size == 0) {\\n            throw new BufferUnderflowException();\\n        }\\n        return get(size - 1);\\n    }\\n\\n    /**\\n     * Removes the element on the top of the stack.\\n     *\\n     * @return the removed element \\n     * @throws BufferUnderflowException  if the stack is empty\\n     */\\n    public Object remove() {\\n        int size = size();\\n        if (size == 0) {\\n            throw new BufferUnderflowException();\\n        }\\n        return remove(size - 1);\\n    }\\n\\n}\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('../Output/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('../Output/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "# display(all_projects_bugreports.iloc[0])\n",
    "# display(all_projects_source_codes.iloc[0].unprocessed_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing composite varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove next line characters:\n",
    "def remove_new_lines(x):\n",
    "    return x.replace('\\n', '').replace('*', '').replace('/', '').replace('\\t','')\n",
    "\n",
    "def clean_new_lines(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(remove_new_lines)\n",
    "    return df\n",
    "\n",
    "# df = clean_new_lines(all_projects_source_codes)\n",
    "# df.iloc[0].unprocessed_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#splitting composite words\n",
    "def findCompositeWords(s):\n",
    "    return ' '.join(re.findall('[A-Z][^A-Z]*', s))   \n",
    "\n",
    "\n",
    "def clean_name_column(df):\n",
    "    df.unprocessed_code = df.unprocessed_code.apply(findCompositeWords)\n",
    "    return df\n",
    "\n",
    "# df = clean_name_column(all_projects_source_codes)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put Kelvin's key word cleaning above this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "# add the Java key words to the stop words\n",
    "\n",
    "# TODO we need to add the operators in here too\n",
    "java_keywords = [\"abstract\", \"assert**\",\"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\", \"const\", \"continue\", \"default\", \"do\", \"double\", \"else\", \"enum\", \"enum****\" \"extends\", \"final\", \"finally\", \"for\", \"goto\",\"goto*\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\",\"interface\", \"long\", \"native\", \"new\", \"package\", \"private\", \"protected\", \"public\", \"return\", \"short\", \"static\", \"strictfp**\",\"strictfp\", \"super\", \"switch\", \"synchornized\", \"this\", \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\"]\n",
    "STOP_WORDS = ENGLISH_STOP_WORDS.union(java_keywords)\n",
    "# STOP_WORDS\n",
    "\n",
    "\n",
    "#vect = CountVectorizer(min_df = 5, stop_words = stop, analyzer = 'word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start working on TF-IDF and Cosine similarity calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COLLECTIONS' 'CONFIGURATION' 'IO' 'LANG' 'DATACMNS' 'DATAMONGO'\n",
      " 'DATAREST' 'LDAP' 'SEC' 'SOCIALFB' 'SPR' 'ELY']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      Licensed to the            Apache            S...\n",
       "1      Licensed to the            Apache            S...\n",
       "2      Licensed to the            Apache            S...\n",
       "3      Licensed to the            Apache            S...\n",
       "4      Licensed to the            Apache            S...\n",
       "                             ...                        \n",
       "471    Licensed to the            Apache            S...\n",
       "472    Licensed to the            Apache            S...\n",
       "473    Licensed to the            Apache            S...\n",
       "474    Licensed to the            Apache            S...\n",
       "475    Licensed to the            Apache            S...\n",
       "Name: unprocessed_code, Length: 476, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# clean up the unprocessed code column\n",
    "def clean_source_code_list(sc_df):\n",
    "    sc_df = clean_new_lines(sc_df)\n",
    "    sc_df = clean_name_column(sc_df)\n",
    "    return sc_df\n",
    "\n",
    "# get clean versions of the dataframes\n",
    "sc_df = clean_source_code_list(all_projects_source_codes)\n",
    "bug_df = clean_source_code_list(all_projects_bugreports)\n",
    "\n",
    "\n",
    "# get a list of the projects and their parent project\n",
    "print(df.project.unique())\n",
    "projects = df.project.unique()\n",
    "commons_projects = projects[0:4]\n",
    "spring_projects = projects[4:11]\n",
    "wildfly_projects = projects[11]\n",
    "\n",
    "# group the data frames\n",
    "grouped_df = sc_df.groupby(df.project)\n",
    "\n",
    "# example of getting a single data frame\n",
    "col_df = grouped_df.get_group(\"COLLECTIONS\")\n",
    "display(col_df)\n",
    "\n",
    "config_df = grouped_df.get_group(commons_projects[1])\n",
    "ely_df = grouped_df.get_group(wildfly_projects)\n",
    "ldap_df = grouped_df.get_group(spring_projects[3])\n",
    "\n",
    "print(config_df.iloc[0].filename)\n",
    "print(col_df.iloc[0].filename)\n",
    "print(ely_df.iloc[0].filename)\n",
    "print(ldap_df.iloc[0].filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_parent_df(group, names):\n",
    "    result = pd.DataFrame\n",
    "    temp = []\n",
    "    for name in names:\n",
    "        temp.append(group.get_group(name))\n",
    "    \n",
    "    result = pd.concate(temp, ignore_index = true)    \n",
    "    return result\n",
    "\n",
    "# don't know if we are looking at these groups OR each of the projects individually\n",
    "commons_df = gen_parent_df(grouped_df, commons_projects)\n",
    "sprint_df = gen_parent_df(grouped_df, spring_projects)\n",
    "wildfly_df = gen_parent_df(grouped_df, wildfly_projects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def calculate_similarity(source_code, bug):\n",
    "    cosSim = cosine_similarity(bug, source_code).flatten()\n",
    "    return cosSim\n",
    "\n",
    "# fit the vectorizer and transform data\n",
    "def transform_data(source_code_data, query_data):\n",
    "    # DO WE SET min_df?  default normalization is l2\n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\").fit(source_code_data)\n",
    "    X = vect.transform(source_code_data)\n",
    "    y = vect.transform(query_data)\n",
    "    similarity = calculate_similarity(X,y)\n",
    "    return X, y, similarity\n",
    "\n",
    "# remove the stem and stop words\n",
    "def stem_stop(text):\n",
    "    stemmer =PorterStemmer(\"english\")\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in STOP_WORDS]\n",
    "    text = list(map(lambda x: stemmer.stem(x), text))\n",
    "    text = ' '.join(text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# first stem and remove stop words from the data frames column\n",
    "# example \n",
    "# TODO don't know if we look through all projects or look at them individually\n",
    "# source_code_df['unprocessed_code'] = source_code_df['unprocessed_code'].map(stem_stop)\n",
    "# bug_df['unprocessed_code'] = bug_df['unprocessed_code'].map(stem_stop)\n",
    "\n",
    "# then get the dataframe column you want to pass as source_code_data and as the query_data(bug)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}